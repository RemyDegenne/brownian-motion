\chapter{{Filtrations, processes and martingales}}\label{chap:filtration_martingale}


First, recall the definitions of a filtration, an adapted process, a (sub)martingale, a stopping time and a stopped process, which are already in Mathlib.


\begin{definition}[Filtration]\label{def:filtration}
  \mathlibok
  \lean{MeasureTheory.Filtration}
A filtration on a measurable space $(\Omega, \mathcal{A})$ with measure $P$ indexed by a preordered set $T$ is a family of sigma-algebras $\mathcal{F} = (\mathcal{F}_t)_{t \in T}$ such that for all $i \le j$, $\mathcal{F}_i \subseteq \mathcal{F}_j$ and for all $t \in T$, $\mathcal{F}_t \subseteq \mathcal{A}$.
\end{definition}


\begin{definition}\label{def:adapted}
  \uses{def:filtration}
  \mathlibok
  \lean{MeasureTheory.Adapted}
A process $X : T \to \Omega \to E$ is said to be adapted with respect to a filtration $\mathcal{F}$ if for all $t \in T$, $X_t$ is $\mathcal{F}_t$-measurable.
\end{definition}


\begin{definition}[Martingale]\label{def:Martingale}
  \uses{def:adapted}
  \mathlibok
  \lean{MeasureTheory.Martingale}
Let $\mathcal{F}$ be a filtration on a measurable space $\Omega$ with measure $P$ indexed by $T$.
A family of functions $M : T \to \Omega \to E$ is a martingale with respect to a filtration $\mathcal{F}$ if $M$ is adapted with respect to $\mathcal{F}$ and for all $i \le j$, $P[M_j \mid \mathcal{F}_i] = M_i$ almost surely.
\end{definition}


\begin{definition}[Submartingale]\label{def:Submartingale}
  \uses{def:adapted}
  \mathlibok
  \lean{MeasureTheory.Submartingale}
Let $\mathcal{F}$ be a filtration on a measurable space $\Omega$ with measure $P$ indexed by $T$.
A family of functions $M : T \to \Omega \to E$ is a submartingale with respect to a filtration $\mathcal{F}$ if $M$ is adapted with respect to $\mathcal{F}$ and for all $i \le j$, $P[M_j \mid \mathcal{F}_i] \ge M_i$ almost surely.
\end{definition}


\begin{definition}[Stopping time]\label{def:IsStoppingTime}
  \uses{def:filtration}
  \mathlibok
  \lean{MeasureTheory.IsStoppingTime}
A stopping time with respect to some filtration $\mathcal{F}$ indexed by $T$ is a function $\tau : \Omega \to T$ such that for all $i$, the preimage of $\{j \mid j \le i\}$ along $\tau$ is measurable with respect to $\mathcal{F}_i$.
\end{definition}

\begin{definition}[$\sigma$-algebra generated by a stopping time]\label{def:StoppingTimeGen}
  \uses{def:IsStoppingTime, def:filtration}
  \mathlibok
  \lean{MeasureTheory.IsStoppingTime.measurableSpace}
  Given a stopping time $\tau$ on a time index $T$, define
  $\mathcal{F}_\tau = \bigcup_{t \in T} \{A \in \mathcal{F} \mid A \cap \{\tau \le t\} \in \mathcal{F}_t\}.$
\end{definition}

\begin{lemma}\label{lem:StoppingTimeGenMono}
  \uses{def:StoppingTimeGen}
  \mathlibok
  \lean{MeasureTheory.IsStoppingTime.measurableSpace_mono}
  Let $\tau, \sigma$ be stopping times such that $\tau \le \sigma$.
  Then, $\mathcal{F}_\tau \subseteq \mathcal{F}_\sigma$.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{definition}[Stopped process]\label{def:stoppedProcess}
  \mathlibok
  \lean{MeasureTheory.stoppedProcess}
Let $X : T \to \Omega \to E$ be a stochastic process and let $\tau : \Omega \to T$.
The stopped process with respect to $\tau$ is defined by
\begin{align*}
  (X^{\tau})_t = \begin{cases}
    X_t & \text{if } t \le \tau \\
    X_{\tau} & \text{otherwise}
  \end{cases}
\end{align*}
\end{definition}


We now give the definition of a filtered probability space satisfying the usual conditions.


\begin{definition}\label{def:leftRightLimitFiltration}
  \uses{def:filtration}
For $\mathcal{F}$ a filtration indexed by $T$ and $t \in T$, we define $\mathcal{F}_{t-} = \bigsqcup_{s < t} \mathcal{F}_s$ (if that supremum is nonempty: we set $\mathcal{F}_{\bot-} = \mathcal{F}_\bot$) and $\mathcal{F}_{t+} = \bigsqcap_{s > t} \mathcal{F}_s$.

Note that $\bigsqcap$ and $\bigsqcup$ denote the infimum and supremum in the lattice of sigma-algebras on $\Omega$.
\end{definition}


\begin{definition}[Right-continuous filtration]\label{def:rightContinuous}
  \uses{def:leftRightLimitFiltration}
  \leanok
  \lean{MeasureTheory.IsRightContinuous}
We say that the filtration is right-continuous if for all $t \in T$, $\mathcal{F}_t = \mathcal{F}_{t+}$.
\end{definition}


\begin{definition}[Usual conditions]\label{def:usualConditions}
  \uses{def:rightContinuous}
  \leanok
  \lean{MeasureTheory.Filtration.UsualConditions}
We say that a filtered probability space $(\Omega, \mathcal{F}, P)$ satisfies the usual conditions if the filtration is right-continuous and if $\mathcal{F}_0$ contains all the $P$-null sets.
\end{definition}


\begin{definition}\label{def:predictableMeasurableSpace}
  \uses{def:filtration}
  \leanok
  \lean{MeasureTheory.Filtration.predictable}
Let $\mathcal{F}$ be a filtration on a measurable space indexed $\Omega$ by a linearly ordered set $T$.
Let $S = \{\{\bot\} \times A \mid A \in \mathcal{F}_\bot\}$ if $T$ has a bottom element and $S = \emptyset$ otherwise.
The predictable sigma-algebra on $T \times \Omega$ is the sigma-algebra generated by the set of sets $\{(t, \infty] \times A \mid t \in T, \: A \in \mathcal{F}_t\} \cup S$.
\end{definition}


\begin{definition}[Predictable process]\label{def:predictable}
  \uses{def:predictableMeasurableSpace}
  \leanok
  \lean{MeasureTheory.IsPredictable}
A process $X : T \to \Omega \to E$ is said to be predictable with respect to a filtration $\mathcal{F}$ if it is measurable with respect to the predictable sigma-algebra on $T \times \Omega$.
\end{definition}


\begin{lemma}\label{lem:Predictable.progressive}
  \uses{def:predictable}
  \leanok
  \lean{MeasureTheory.IsPredictable.progMeasurable}
A predictable process is progressively measurable.
\end{lemma}

\begin{proof}\leanok
Let $X : T \times \Omega \to E$ be a predictable process, we will show that it is progressively measurable. Namely, fixing $t \in T$, denoting
$$\iota_t : [0, t] \to T : s \mapsto s$$
we need to show that $\iota_t \circ X : [0, t] \times \Omega \to E$ is measurable with respect to $\mathcal{B}([0, t]) \otimes \mathcal{F}_t$.

Denoting $\Sigma_{\mathcal{F}}$ for the predictable $\sigma$-algebra generated by $\mathcal{F}$, as $u$ is predictable, we have that $X^{-1}(\mathcal{B}(E)) \le \Sigma_{\mathcal{F}}$. Thus, to show that $\iota_t \circ X$ is $\mathcal{B}([0, t]) \otimes \mathcal{F}_t$-measurable, it suffices to show that $\iota_t^{-1}(\Sigma_{\mathcal{F}}) \le \mathcal{B}([0, t]) \otimes \mathcal{F}_t$. In particular, as
$$\Sigma_{\mathcal{F}} = \sigma(\{(s, \infty) \times A \mid A \in \mathcal{F}_s\} \cup \{\{\perp\} \times A \mid A \in \mathcal{F}_\perp\})$$
is suffices to show that sets of the form $\iota_t^{-1}((s, \infty) \times A)$ for some $s \in T, A \in \mathcal{F}_s$ and $\iota_t^{-1}(\{\bot\} \times A)$ for some $A \in \mathcal{F}_\bot$ are $\mathcal{B}([0, t]) \otimes \mathcal{F}_t$-measurable.

Indeed, if $A \in \mathcal{F}_\bot$
$$\iota_t^{-1}(\{\bot\} \times A) = \{\bot\} \times A$$
while for any $s \in T$ and $A \in \mathcal{F}_s$,
$$\iota_t^{-1}((s, \infty) \times A) = \begin{cases}
    \varnothing, & t < s\\
    (s, t] \times A, & s \le t.
\end{cases}$$
By the monotonicity of the filtration $\mathcal{F}$, all of these cases are $\mathcal{B}([0, t]) \otimes \mathcal{F}_t$-measurable allowing us to conclude.
\end{proof}

\begin{lemma}\label{lem:predictable_Ioc_prod}
  \uses{def:predictableMeasurableSpace}
  \leanok
  \lean{MeasureTheory.measurableSet_predictable_Ioc_prod}
Sets of the form $(s, t] \times A$ for any $A \in \mathcal{F}_s$ is measurable with respect to the predictable $\sigma$-algebra.
\end{lemma}
\begin{proof}\leanok
For $t \le s$, the set in question is empty and thusly, trivially measurable. On the other hand, for $s < t$, measurability follows as
$(s, t] \times A = (s, \infty) \times A \setminus (t, \infty) \times A$.
\end{proof}

\begin{lemma}\label{lem:predictable_nat_iff}
  \uses{def:predictable}
  \leanok
  \lean{MeasureTheory.isPredictable_iff_measurable_add_one}
Let $X : \mathbb{N} \to \Omega \to E$ be a stochastic process and let $\mathcal{F}$ be a filtration indexed by $\mathbb{N}$.
Then $X$ is predictable if and only if $X_0$ is $\mathcal{F}_0$-measurable and for all $n \in \mathbb{N}$, $X_{n+1}$ is $\mathcal{F}_n$-measurable.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:predictable_Ioc_prod}
Suppose first that $X$ is predictable. Straightaway, $X_0$ is $\mathcal{F}_0$-measurable as predictable implies progressively measurable which in turn implies adapted.

Fixing $n$, we observe that for any $S \in \mathcal{B}(E)$,
$$X_{n + 1}^{-1}(S) = \{\omega \mid (n + 1, \omega) \in X^{-1}(S)\} = \pi^{-1}(\iota^{-1}(X^{-1}(S)))$$
where
$$\pi : \Omega \to \{n + 1\} \times \Omega : \omega \mapsto (n + 1, \omega)$$
and
$$\iota : \{n + 1\} \times \Omega \to T \times \Omega : (n + 1, \omega) \mapsto (n + 1, \omega).$$
As $X^{-1}(S) \in \Sigma_{\mathcal{F}}$ -- the predictable $\sigma$-algebra, it suffices to show that $\pi^{-1}(\iota^{-1}(\Sigma_{\mathcal{F}})) \in \mathcal{F}_n$. To this end, we again only need to show these for the generating sets of $\Sigma_{\mathcal{F}}$:
\begin{itemize}
    \item For $A \in \mathcal{F}_0$, measurability is clear as $\iota^{-1}(\{0\} \times A) = \varnothing$.
    \item Similarly, for $m > n$ and $A \in \mathcal{F}_m$, $\iota^{-1}((m, \infty) \times A) = \varnothing$.
    \item For $m \le n$ and $A \in \mathcal{F}_m \le \mathcal{F}_n$ we have that $\pi^{-1}(\iota^{-1}((m, \infty) \times A)) = A$ which is $\mathcal{F}_n$ measurable by the monotonicity of the filtration.
\end{itemize}

Now, supposing $X_0$ is $\mathcal{F}_0$-measurable and $X_{n + 1}$ is $\mathcal{F}_n$-measurable, we will show that $X$ is predictable. Indeed, fixing $S \in \mathcal{B}(E)$, we have
$$X^{-1}(S) = \bigcup_{n \in \mathbb{N}} \{n\} \times X_n^{-1}(S) = {0} \times X_0^{-1}(S) \cup \bigcup_{n \in \mathbb{N}} \{n + 1\} \times X_{n + 1}^{-1}(S).$$
Thus, as $\{0\} \times X_0^{-1}(S) \in \Sigma_{\mathcal{F}}$ by construction and $\{n + 1\} \times X_{n + 1}^{-1}(S) = (n, n + 1] \times X_{n + 1}^{-1}(S) \in \Sigma_{\mathcal{F}}$ by Lemma~\ref{lem:predictable_Ioc_prod} and the fact that $X_{n + 1}^{-1}(S) \in \mathcal{F}_n$, we have that $X^{-1}(S) \in \Sigma_{\mathcal{F}}$ as required.
\end{proof}

\begin{lemma}[Optional sampling (discrete time)]\label{lem:optionalSampling_discrete}
  \uses{def:Martingale, def:IsStoppingTime}
  \mathlibok
  \lean{MeasureTheory.Martingale.stoppedValue_min_ae_eq_condExp}
  Let $X$ be a discrete time martingale with respect to the filtration $\mathcal{F}$ and let
  $\tau, \sigma$ be stopping times. Then, if $\tau$ is bounded, we have that
  $X_{\tau \wedge \sigma} = P[X_{\tau} \mid \mathcal{F}_{\sigma}]$.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}\label{lem:conExpUI}
  If $S$ is a family of uniformly integrable functions and $\mathcal{A}$ is a family of $\sigma$-algebras,
  then the family $\{P[X \mid \mathcal{G}]\}_{X \in S, \mathcal{G} \in \mathcal{A}}$ is uniformly integrable.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}[Vitali convergence theorem]\label{lem:vitali}
  \mathlibok
  \lean{MeasureTheory.tendstoInMeasure_iff_tendsto_Lp_finite}
  A sequence of functions converges in $L^1$ if and only if it converges in probability and is uniformly integrable.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}\label{lem:stoppingTime_approximation}
  \uses{def:IsStoppingTime}
  Let $\tau$ be a stopping time on $\overline{\mathbb{R}_+}$ with respect to the filtration $\mathcal{F}$.
  Then defining $\tau_n =  2^{-n} \lceil 2^n \tau \rceil$,
  we have that for each $n$, $\tau_n$ is a stopping time and $\tau_n \downarrow \tau$ as $n \to \infty$.
\end{lemma}

\begin{proof}
  Clearly $\tau_n \downarrow \tau$ as $n \to \infty$ and so it remains to show that each $\tau_n$ is a stopping time.
  Indeed,
  \[\{\tau_n \le t\} = \{\tau \le 2^{-n} \lfloor 2^n t\rfloor\}
    \in \mathcal{F}_{2^{-n} \lfloor 2^n t\rfloor} \subseteq \mathcal{F}_t\]
  where the last inclusion follows as \(2^{-n} \lfloor 2^n t\rfloor \le t\).
\end{proof}


\begin{lemma}[Optional sampling (continuous time)]\label{lem:optionalSampling}
  \uses{def:Martingale, def:IsStoppingTime, def:rightContinuous}
  Let $X$ be a right-continuous martingale with respect to the filtration $\mathcal{F}$. Then for
  any bounded stopping times $\sigma, \tau$, we have that
  $X_{\sigma \wedge \tau} = P[X_{\tau} \mid \mathcal{F}_{\sigma}]$ almost surely.
\end{lemma}

\begin{proof}
  \uses{lem:stoppingTime_approximation, lem:optionalSampling_discrete, lem:conExpUI, lem:vitali, lem:StoppingTimeGenMono}
  Fixing $A \in \mathcal{F}_{\sigma}$, we need to show that $P[X_{\tau} \mathbb{I}_A] = P[X_{\sigma \wedge \tau} \mathbb{I}_A]$.

  Denoting $\tau_n = 2^{-n} \lceil 2^n \tau \rceil$ and $\sigma_n = 2^{-n} \lceil 2^n \sigma \rceil$ as in
  Lemma~\ref{lem:stoppingTime_approximation}, $(\tau_n), (\sigma_n)$ are sequences of stopping times
  decreasing to $\tau$ and $\sigma$ respectively. Now, as $\tau_n, \sigma_n$ take values in a countable set,
  we have by the discrete time optional sampling theorem (Lemma~\ref{lem:optionalSampling_discrete}) that
  $$X_{\sigma_n \wedge \tau_n} = P[X_{\tau_n} \mid \mathcal{F}_{\sigma_n}]$$
  and so, as \(\mathcal{F}_{\sigma} \subseteq \mathcal{F}_{\sigma_n}\) by Lemma~\ref{lem:StoppingTimeGenMono},
  we have that $P[X_{\sigma_n \wedge \tau_n} \mathbb{I}_A] = P[X_{\tau_n} \mathbb{I}_A]$.
  On the other hand, again by optional sampling, we have $X_{\tau_n} = P[X_{\tau_1} \mid \mathcal{F}_{\tau_n}]$ and
  $X_{\sigma_n} = P[X_{\sigma_1} \mid \mathcal{F}_{\sigma_n}]$. In particular, both sequences $(X_{\tau_n})$
  and $(X_{\sigma_n \wedge \tau_n}) = (P[X_{\tau_n} \mid \mathcal{F}_{\sigma_n}])$ are UI by
  Lemma~\ref{lem:conExpUI} (extended to a family of functions). Thus, as $X$ is right-continuous,
  $(X_{\sigma_n \wedge \tau_n}, X_{\tau_n}) \to (X_{\sigma \wedge \tau}, X_{\tau})$ a.s. we have
  $P[X_{\tau} \mathbb{I}_A] = P[X_{\sigma \wedge \tau} \mathbb{I}_A]$
  by the Vitali convergence theorem (Lemma~\ref{lem:vitali}) as desired.
\end{proof}

\section{Local martingales}


This section contains material taken mostly from \cite[Chapters 10 and 18]{kallenberg2021} and \cite{almostsuremath}.


\begin{definition}\label{def:preLocalizingSequence}
  \uses{def:IsStoppingTime}
  \leanok
  \lean{ProbabilityTheory.IsPreLocalizingSequence}
A pre-localizing sequence is a sequence of stopping times $(\tau_n)_{n \in \mathbb{N}}$ such that $\tau_n \to \infty$ as $n \to \infty$ (a.s.).
\end{definition}


\begin{definition}[Localizing sequence]\label{def:localizingSequence}
  \uses{def:preLocalizingSequence}
  \leanok
  \lean{ProbabilityTheory.IsLocalizingSequence}
A localizing sequence is a sequence of stopping times $(\tau_n)_{n \in \mathbb{N}}$ such that $\tau_n$ is non-decreasing and $\tau_n \to \infty$ as $n \to \infty$ (a.s.).
That is, it is a pre-localizing sequence that is also almost surely non-decreasing.
\end{definition}


\begin{lemma}\label{lem:localizingSequence_const_top}
  \uses{def:localizingSequence}
  \leanok
  \lean{ProbabilityTheory.isLocalizingSequence_const_top}
The constant sequence $\tau_n = \infty$ is a localizing sequence.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}\label{lem:localizingSequence_min}
  \uses{def:localizingSequence}
  \leanok
  \lean{ProbabilityTheory.IsLocalizingSequence.min}
Let $(\sigma_n), (\tau_n)$ be localizing sequences.
Then $(\sigma_n \wedge \tau_n)$ is a localizing sequence.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{definition}[Local property]\label{def:locally}
  \uses{def:localizingSequence, def:stoppedProcess}
  \leanok
  \lean{ProbabilityTheory.Locally, ProbabilityTheory.Locally.localSeq}
Let $P$ be a class of stochastic processes (or equivalently a predicate on stochastic processes).
We say that a stochastic process $X : T \to \Omega \to E$ is locally in $P$ (or satisfies $P$ locally) if there exists a localizing sequence $(\tau_n)_{n \in \mathbb{N}}$ such that for all $n \in \mathbb{N}$, the process $X^{\tau_n}\mathbb{I}_{\tau_n > 0}$ is in $P$ (in which $X^{\tau_n}$ denotes the stopped process).
We denote the class of processes that are locally in $P$ by $P_{\mathrm{loc}}$.
\end{definition}


\begin{lemma}\label{lem:implies_locally}
  \uses{def:locally}
  \leanok
  \lean{ProbabilityTheory.locally_of_prop}
For any class of processes $P$, we have $P \subseteq P_{\mathrm{loc}}$.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:localizingSequence_const_top}
Take $\tau_n = \infty$ for all $n$.
\end{proof}


\begin{lemma}\label{lem:locally_mono}
  \uses{def:locally}
  \leanok
  \lean{ProbabilityTheory.Locally.mono}
If $P \subseteq Q$ then $P_{\mathrm{loc}} \subseteq Q_{\mathrm{loc}}$.
\end{lemma}

\begin{proof}\leanok
Let $X \in P_{\mathrm{loc}}$.
Then there exists a localizing sequence $(\tau_n)_{n \in \mathbb{N}}$ such that for all $n \in \mathbb{N}$, $X^{\tau_n}\mathbb{I}_{\tau_n > 0} \in P$.
Since $P \subseteq Q$, for all $n \in \mathbb{N}$, $X^{\tau_n}\mathbb{I}_{\tau_n > 0} \in Q$.
Thus $X \in Q_{\mathrm{loc}}$.
\end{proof}


\begin{definition}\label{def:stable}
  \uses{def:locally}
  \leanok
  \lean{ProbabilityTheory.IsStable}
A class of stochastic processes $P$ is stable if whenever $X$ is in $P$, then for any stopping time $\tau$, the process $X^{\tau}\mathbb{I}_{\tau > 0}$ is also in $P$.
\end{definition}


\begin{lemma}\label{lem:isStable_locally}
  \uses{def:locally, def:stable}
  \leanok
  \lean{ProbabilityTheory.IsStable.isStable_locally}
If $P$ is a stable class of processes, then $P_{\mathrm{loc}}$ is also stable.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}\label{lem:locally_inter}
  \uses{def:locally, def:stable}
  \leanok
  \lean{ProbabilityTheory.locally_and}
If $P, Q$ are stable classes of processes then $(P\cap Q)_{\mathrm{loc}} = P_{\mathrm{loc}}\cap Q_{\mathrm{loc}}$.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:localizingSequence_min}
The forward direction is trivial so we only provide proof for the reverse.

Suppose that $X \in P_{\mathrm{loc}}\cap Q_{\mathrm{loc}}$. Then, there exists localizing sequences $(\tau_n)_{n \in \mathbb{N}}$ and $(\sigma_n)_{n \in \mathbb{N}}$ such that $X^{\tau_n} \mathbb{I}_{\tau_n > 0}\in P$ and $X^{\sigma_n} \mathbb{I}_{\sigma_n > 0} \in Q$. Consequently, by the stability of $P$,
\[X^{\sigma_n \wedge \tau_n} \mathbb{I}_{\sigma_n \wedge \tau_n > 0} = (X^{\tau_n} \mathbb{I}_{\tau_n > 0})^{\sigma_n \wedge \tau_n} \mathbb{I}_{\sigma_n \wedge \tau_n > 0} \in P.\]
Similarly, by the stability of $Q$, $X^{\sigma_n \wedge \tau_n} \mathbb{I}_{\sigma_n \wedge \tau_n > 0} \in Q$. Thus, as $\sigma_n \wedge \tau_n$ is a localizing sequence by Lemma~\ref{lem:localizingSequence_min} and $X^{\sigma_n \wedge \tau_n} \mathbb{I}_{\sigma_n \wedge \tau_n > 0} \in P \cap Q$ for all $n$, it follows that $X \in (P \cap Q)_{\mathrm{loc}}$
\end{proof}

\begin{lemma}\label{lem:isLocalizingSequence_of_isPreLocalizingSequence}
  \uses{def:localizingSequence, def:rightContinuous}
  \leanok
  \lean{ProbabilityTheory.isLocalizingSequence_of_isPreLocalizingSequence}
If $(\tau_n)_{n \in \mathbb{N}}$ is a pre-localizing sequence, then the sequence defined by $\tau'_n = \inf_{m \ge n} \tau_m$ is a localizing sequence.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}\label{lem:locally_of_isPreLocalizingSequence}
  \uses{def:locally, def:localizingSequence, def:stable, def:rightContinuous, def:preLocalizingSequence}
  \leanok
  \lean{ProbabilityTheory.locally_of_isPreLocalizingSequence}
Let $P$ be a stable class of processes and let $(\tau_n)_{n \in \mathbb{N}}$ be a pre-localizing sequence such that for all $n \in \mathbb{N}$, $X^{\tau_n}\mathbb{I}_{\tau_n > 0}$ is in $P$.
If the filtration is right-continuous, then $X$ is locally in $P$.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:isLocalizingSequence_of_isPreLocalizingSequence}

\end{proof}


\begin{lemma}\label{lem:isPreLocalizingSequence_of_isLocalizingSequence}
  \uses{def:preLocalizingSequence, def:localizingSequence}
  \leanok
  \lean{ProbabilityTheory.isPreLocalizingSequence_of_isLocalizingSequence}
Let $(\tau_n)_{n \in \mathbb{N}}$ be a localizing sequence and let $(\sigma_{n,k})_{k \in \mathbb{N}}$ be a localizing sequence for each $n$.
Then, there exists a strictly increasing sequence $(k_n)_{n \in \mathbb{N}}$ such that the sequence defined by $\tau'_n = \tau_n \wedge \sigma_{n,k_n}$ is a pre-localizing sequence.
\end{lemma}

\begin{proof}\leanok

\end{proof}


\begin{lemma}\label{lem:locally_locally}
  \uses{def:locally, def:stable}
  \leanok
  \lean{ProbabilityTheory.locally_locally}
Suppose that the filtration is right-continuous.
For any stable class of processes $P$, we have $(P_{\mathrm{loc}})_{\mathrm{loc}} = P_{\mathrm{loc}}$.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:locally_of_isPreLocalizingSequence, lem:isStable_locally, lem:isPreLocalizingSequence_of_isLocalizingSequence}
Let $X$ be a process in $(P_{\mathrm{loc}})_{\mathrm{loc}}$.
By definition there exists a localizing sequence $(\tau_n)_{n \in \mathbb{N}}$ such that for all $n \in \mathbb{N}$, $X^{\tau_n}\mathbb{I}_{\tau_n > 0}$ is in $P_{\mathrm{loc}}$.
By definition of $P_{\mathrm{loc}}$, for each $n$ there exists a localizing sequence $(\sigma_{n,k})_{k \in \mathbb{N}}$ such that for all $k \in \mathbb{N}$, $(X^{\tau_n}\mathbb{I}_{\tau_n > 0})^{\sigma_{n,k}}\mathbb{I}_{\sigma_{n,k} > 0}$ is in $P$.

For each $n$, since $\sigma_{n,k} \to \infty$ a.s. as $k \to \infty$, we may choose $k_n \in \mathbb{N}$ such that $P(\sigma_{n,k_n} < \tau_n \wedge n) \le 2^{-n}$.
Let $\tau'_n = \tau_n \wedge \sigma_{n,k_n}$. $\tau_n' \to \infty$ by the Borel-Cantelli lemma.
Let $\tau''_n = \inf_{m \ge n} \tau'_m$.
Then $(\tau''_n)_{n \in \mathbb{N}}$ is a localizing sequence.

It remains to argue that by stability of $P$, $X^{\tau''_n}\mathbb{I}_{\tau''_n > 0}$ is in $P$ for all $n$.
Indeed, $X^{\tau''_n} = ((X^{\tau_n}\mathbb{I}_{\tau_n > 0})^{\sigma_{n,k_n}}\mathbb{I}_{\sigma_{n,k_n} > 0})^{\tau''_n}\mathbb{I}_{\tau''_n > 0}$. $(X^{\tau_n}\mathbb{I}_{\tau_n > 0})^{\sigma_{n,k_n}}\mathbb{I}_{\sigma_{n,k_n} > 0}$ is in $P$ by construction and $P$ is stable.
\end{proof}


\begin{lemma}[Local implication from global implication]\label{lem:local_induction}
  \uses{def:locally, def:stable}
  \leanok
  \lean{ProbabilityTheory.locally_induction}
Suppose that the filtration is right-continuous.
Let $P, Q$ be two classes of stochastic processes such that $P \subseteq Q_{\mathrm{loc}}$ and $Q$ is stable.
Let $X$ be a stochastic process that satisfies $P$ locally.
Then $X$ satisfies $Q$ locally.
In short, if $P$ implies $Q$ locally, then $P$ locally implies $Q$ locally.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:locally_locally, lem:locally_mono}
Since $X \in P_{\mathrm{loc}}$, then $X \in (Q_{\mathrm{loc}})_{\mathrm{loc}}$ by assumption and Lemma~\ref{lem:locally_mono}.
By Lemma \ref{lem:locally_locally}, $(Q_{\mathrm{loc}})_{\mathrm{loc}} = Q_{\mathrm{loc}}$.
Thus $X \in Q_{\mathrm{loc}}$.
\end{proof}


\begin{definition}[Local martingale]\label{def:IsLocalMartingale}
  \uses{def:Martingale, def:locally}
  \leanok
  \lean{ProbabilityTheory.IsLocalMartingale}
A stochastic process is a local martingale if it is locally a martingale in the sense of Definition~\ref{def:locally}.
That is, there exists a localizing sequence $(\tau_n)_{n \in \mathbb{N}}$ such that for all $n \in \mathbb{N}$, the process $M^{\tau_n}\mathbb{I}_{\tau_n > 0}$ is a martingale.
\end{definition}


\begin{definition}\label{def:IsLocalSubmartingale}
  \uses{def:Submartingale, def:localizingSequence, def:stoppedProcess}
  \leanok
  \lean{ProbabilityTheory.IsLocalSubmartingale}
A stochastic process is a local submartingale if it is locally a submartingale in the sense of Definition~\ref{def:locally}.
That is, there exists a localizing sequence $(\tau_n)_{n \in \mathbb{N}}$ such that for all $n \in \mathbb{N}$, the process $M^{\tau_n}\mathbb{I}_{\tau_n > 0}$ is a submartingale.
\end{definition}


\begin{lemma}\label{lem:Martingale.IsLocalMartingale}
  \uses{def:IsLocalMartingale}
  \leanok
  \lean{ProbabilityTheory.Martingale.IsLocalMartingale}
Every martingale is a local martingale.
\end{lemma}

\begin{proof}\leanok
  \uses{lem:implies_locally}
This follows from Lemma \ref{lem:implies_locally}.
\end{proof}


\begin{lemma}\label{lem:stable_IsMartingale}
  \uses{def:Martingale, def:stable}
  \leanok
  \lean{ProbabilityTheory.isStable_martingale}
The class of martingales is stable. That is, if $M$ is a martingale and $\tau$ is a stopping time, then the stopped process $M^{\tau}\mathbb{I}_{\tau > 0}$ is also a martingale.
\end{lemma}

\begin{proof}
  \uses{lem:optionalSampling}
  Fixing $s \le t \in T$, as $\{\tau > 0\} \in \mathcal{F}_0 \subseteq \mathcal{F}_s$, we have
  $$P[M^{\tau}_t \mathbb{I}_{\tau > 0} \mid \mathcal{F}_s] = \mathbb{I}_{\tau > 0}P[M_{\tau \wedge t} \mid \mathcal{F}_{s}].$$
  Thus, as $\tau \wedge t$ is a bounded stopping time, we have by the optional stopping theorem
  (Lemma~\ref{lem:optionalSampling}) that $P[M_{\tau \wedge t} \mid \mathcal{F}_{s}] = M_{(\tau \wedge t) \wedge s} = M_{\tau \wedge s}$
  and so, $P[M^{\tau}_t \mathbb{I}_{\tau > 0} \mid \mathcal{F}_s] = M^{\tau}_s \mathbb{I}_{\tau > 0}$ as required.
\end{proof}


\begin{lemma}\label{lem:stable_IsSubmartingale}
  \uses{def:Submartingale, def:stable}
  \leanok
  \lean{ProbabilityTheory.isStable_submartingale}
The class of submartingales is stable. That is, if $M$ is a submartingale and $\tau$ is a stopping time, then the stopped process $M^{\tau}\mathbb{I}_{\tau > 0}$ is also a submartingale.
\end{lemma}

\begin{proof}

\end{proof}


\begin{theorem}\label{thm:IsLocalMartingale.eq_zero_of_finiteVariation}
  \uses{def:IsLocalMartingale}
Let $M$ be a continuous local martingale with $M_0 = 0$. If $M$ is also a finite variation process, then $M_t = 0$ for all $t$.
\end{theorem}

\begin{proof}

\end{proof}




\section{Doob-Meyer class}


\begin{definition}\label{def:locallyIntegrableSup}
  \uses{def:locally}
We say that a stochastic process is integrable if for all $t$, $E[\Vert X_t \Vert] < \infty$.
A process has locally integrable supremum if $\sup_{t \in T} \Vert X_t \Vert$ is locally integrable.
\end{definition}


\begin{definition}[Doob-Meyer class, class D]\label{def:classD}
  \uses{def:IsStoppingTime}
A stochastic process $(X_t)$ is of class D (or in the Doob-Meyer class) if it is adapted and the set $\{X_\tau \mid \tau \text{ is a finite stopping time}\}$ is uniformly integrable.
\end{definition}


\begin{definition}[Class DL]\label{def:classDL}
  \uses{def:IsStoppingTime}
A stochastic process $(X_t)$ is of class DL if it is adapted and for all $t \ge 0$, the set $\{X_\tau \mid \tau \text{ is a stopping time with } \tau \le t\}$ is uniformly integrable.
\end{definition}


\begin{lemma}\label{lem:Submartingale.classDL}
  \uses{def:Submartingale, def:classDL}
Every positive cadlag submartingale is of class DL.
\end{lemma}

\begin{proof}

\end{proof}


\begin{lemma}\label{lem:Submartingale.classD_iff_uniformIntegrable}
  \uses{def:Submartingale, def:classD}
A positive cadlag submartingale is of class D if and only if it is uniformly integrable
\end{lemma}

\begin{proof}
  \uses{lem:Submartingale.classDL}

\end{proof}


\begin{lemma}\label{lem:Martingale.classDL}
  \uses{def:Martingale, def:classDL}
Every cadlag martingale is of class DL.
\end{lemma}

\begin{proof}
  \uses{lem:Submartingale.classDL}

\end{proof}

\begin{lemma}\label{lem:Martingale.classD_iff_uniformIntegrable}
  \uses{def:Martingale, def:classD}
A cadlag martingale is of class D if and only if it is uniformly integrable.
\end{lemma}

\begin{proof}
  \uses{lem:Martingale.classDL, lem:Submartingale.classD_iff_uniformIntegrable}

\end{proof}


\begin{lemma}\label{lem:isStable_classD}
  \uses{def:stable}
The class D is stable.
\end{lemma}

\begin{proof}

\end{proof}


% todo: this and the next lemma are proved together, with whatever chain of implications is easiest
\begin{lemma}\label{lem:locally_classD_iff_locallyIntegrableSup}
  \uses{def:classD, def:locallyIntegrableSup, def:locally}
A cadlag adapted process is locally of class D if and only if it has locally integrable supremum.
\end{lemma}

\begin{proof}

\end{proof}


% todo: this and the previous lemma are proved together, with whatever chain of implications is easiest
\begin{lemma}\label{lem:locally_classD_iff_locally_classDL}
  \uses{def:classD, def:classDL, def:locally}
A cadlag adapted process is locally of class D if and only if it is locally of class DL.
\end{lemma}

\begin{proof}

\end{proof}


\begin{lemma}\label{lem:IsLocalSubmartingale.locally_classD}
  \uses{def:IsLocalSubmartingale, def:classD, def:locally}
Every local submartingale is locally of class D.
\end{lemma}

\begin{proof}
  \uses{lem:local_induction, lem:stable_IsSubmartingale}
By Lemma~\ref{lem:local_induction}, it suffices to show that if $X$ is a submartingale then it is locally of class D.

TODO
\end{proof}


\begin{lemma}\label{lem:IsLocalMartingale.locally_classD}
  \uses{def:IsLocalMartingale, def:classD, def:locally}
Every local martingale is locally of class D.
\end{lemma}

\begin{proof}

\end{proof}


\begin{lemma}\label{lem:IsLocalMartingale.martingale_iff_classDL}
  \uses{def:IsLocalMartingale, def:classDL, def:Martingale}
A local martingale is a martingale if and only if it is of class DL.
\end{lemma}

\begin{proof}

\end{proof}


\begin{lemma}\label{lem:IsLocalSubmartingale.submartingale_iff_classDL_of_nonnegative}
  \uses{def:IsLocalSubmartingale, def:classDL, def:Submartingale}
A nonnegative local submartingale is a submartingale if and only if it is of class DL.
\end{lemma}

\begin{proof}

\end{proof}
