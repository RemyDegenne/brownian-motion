\documentclass[lean]{DraftAFM}

\input{preamble}

\makeatletter
\newcommand\leanlink{\begingroup\catcode`\#=12\relax\@leanlink}
\newcommand\@leanlink[2]{\endgroup
\href{#1}
{\texttt{\detokenize{#2}}}}

\title[Formalization of Brownian motion in Lean]{Formalization of Brownian motion in Lean}
\author[R. Degenne, M. Himmel, D. Ledvinka, E. Marion, P. Pfaffelhuber]{
  Rémy Degenne, Markus Himmel, David Ledvinka, Etienne Marion, Peter Pfaffelhuber}


\authorinfo[R. Degenne]{Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189-CRIStAL, F-59000 Lille, France}{remy.degenne@inria.fr}

\authorinfo[M. Himmel]{University of XYZ, Country}{markus.himmel@example.com}

\authorinfo[D. Ledvinka]{University of XYZ, Country}{david.ledvinka@example.com}

\authorinfo[E. Marion]{University of XYZ, Country}{etienne.marion@example.com}

\authorinfo[P. Pfaffelhuber]{University of Freiburg, Germany}{p.p@stochastik.uni-freiburg.de}


\VOLUME{Todo}
\YEAR{Todo}
\NUMBER{Todo}
\firstpage{1}
\DOI{Todo}
\receiveddate{Todo}
\finaldate{Todo}
\accepteddate{Todo}


%Some useful commands:
%\mathlib{}
%\Lean{}
%\leanlink{url}{this is a link to Lean code}

%Example of Lean code:
%\begin{lstlisting}
%/-- A process `X : T → Ω → E` has independent increments if for any `n ≥ 2` and `t₁ ≤ ... ≤ tₙ`,
%the random variables `X t₂ - X t₁, X t₃ - X t₂, ...` are independent. -/
%def HasIndepIncrements {Ω T E : Type*} {mΩ : MeasurableSpace Ω} [Sub E]
%    [Preorder T] [MeasurableSpace E] (X : T → Ω → E) (P : Measure Ω) : Prop :=
%  ∀ n, ∀ t : Fin (n + 2) → T, Monotone t →
%    iIndepFun (fun i : Fin (n + 1) ↦ X (t i.succ) - X (t i.castSucc)) P
%\end{lstlisting}

%Inline code: \lstinline|sorry|

\begin{abstract}
Concise abstract.
\end{abstract}

% please fill in
\msc{}

% please fill in
\keywords{Formalization, Mathlib, Lean, Brownian motion}

\addbibresource{biblio.bib}

\renewcommand{\lean}[1]{\lstinline[language=lean]{#1}}

\begin{document}

\section{Introduction}

\subsection{Mathematical background}
\sloppy Brownian motion is arguably one of the most important stochastic processes (e.g.\ \cite{karatzas1991brownian, morters2010brownian}), and is used as a modeling tool across all sciences (physics: e.g.\ \cite{einstein1906theorie, bian2016111}; biology: e.g.\ \cite{erban2014molecular}; finance: e.g.\ \cite{davis2006louis}). Mathematically, Brownian Motion led to Wiener measure \cite{wiener1923differential}, which is the first instance of a probability measure on a function space, but also to developments such as Stochastic (Partial) Differential equations (see e.g.\ \cite{hairer2009introduction}).

Let us briefly describe Brownian motion $X = (X_t)_{t\geq 0}$. There are several interesting features (considering the one-dimensional version and if $X_0=0$):
\begin{itemize}
\item It has a normal distirbution at all times; more precisely, for any $t_1,...,t_n > 0$, we have that $(X_{t_1},...,X_{t_n})$ has a multivariate normal distribution, with $\mathbf E[X_{t_i}] = 0$ and $\mathbf{COV}(X_{t_i}, X_{t_j}) = t_i \wedge t_j$ (in other words, $X$ is a Gaussian process);
\item Its states after time $t$ are independent of states before $t$ given $X_t$, or $\mathbb P(X_{t+s} \in . | (X_r)_{r\leq t}) = \mathbb P(X_{t+s} \in . | X_t)$ for $s,t \ge 0$, i.e.\ Brownian Motion is a Markov process;
\item It has independent increments, which only depend on the evolved time, i.e.\ $X_s$ and $X_t - X_s$ are independent, and $X_t - X_s$ is a function of $t-s$, i.e.\ it is a Lévy process;
\item It describes a fair game (usually denoted a martingale), i.e.\ $\mathbb E[X_{t+s} | (X_r)_{r\leq t}] = X_t$ for $s,t \geq 0$; interestingly, it is the only stochastic process with continuous paths such that $(X_t)_{t\geq 0}$ and $(X_t^2 - t)_{t\geq 0}$ are martingales;
\item It has continuous paths (almost surely); more precisely, it has Hölder-continuous paths for any coefficient $\beta < \tfrac 12$; as a consequence, its paths are nowhere differentiable, almost surely;
\end{itemize}
The goal of the present paper is to describe a formalization project of Brownian Motion using Lean \cite{lean}, building on its mathematical library. Since Mathlib \cite{mathlib} has a decent amount of measure theory already included, but is still lacking some fundamentals, we describe our way to a full formalization using the following steps:
\begin{itemize}
\item {\em The Carathéodory and Kolmogorov Extension Theorems:} Constructing a probability measure on an uncountable infinite product (i.e.\ the distribution of a stochastic process) is not straight-forward, since the corresponding product of $\sigma$-algebras is too large. Rather, one uses the $\sigma$-algebra defined by all finite (or countably infinite) projections, and constructs a probability measure by extension from all finite dimensional possibilities, which is the content of the Kolmogorov Extension Theorem. This result is in fact an application of a more general result, the Carathèodory Extension Theorem. In this step, we need that the family of finite dimensional distirbutions has a consistency property (i.e.\ it forms a projective family).
\item {\em Gaussian Measures and characteristic functions:} Defining a one-dimensional normal distribution is straight-forward using its density with respect to Lebesgue measure, and concrete calulations are often possible using the density. In the multi-dimensional case, which we have to work with extensively, it is often much more convenient to use characteristic functions, which are known to characterize probability measures uniquely. In particular, they can be used to show that linear maps (e.g.\ projections) of Gaussian measures are Gaussian. This approach is fundamental to show that finite dimensional distirbutions of Brownian Motion indeed form a projective family.
\item {\em The Kolmogorov-Chentsov Theorem:} We are aiming for a stochastic process with continuous paths. The classical Kolmogorov Chentsov theorem gives a criterion in terms of some moment bounds if the set of times is a subset of $\mathbb R^d$; see e.g.\ \cite{kallenberg2021}. Here, we use a modern version for existence of a modification of a stochastic process with continuous paths, based on a more general set of times \cite{kratschmer2023kolmogorov}.
\item {\em Construction of Brownian motion and Wiener measure on $\R_+$:} Putting all of the above together gives a continuous Gaussian stochastic process with the correct distribution, i.e.\ Brownian Motion. From this, we can also define a probability measure on (the Polish space) of continuous functions $\mathbb R_+ \to \mathbb R$. This is usually called the Wiener measure.
\end{itemize}
It is important to realize that probability theory comes with a duality between random variables (or stochastic processes) and their distributions (or laws), which are probability measures. In the case of stochastic processes, the latter are defined on the (often uncountable infinite) product on the state space. While some properties of a stochastic process are only dependent on their distribution (e.g.\ being a Gaussian process), other properties depend on more refined properties (e.g.\ having continuous paths). We account for this duality in our code by introducing in the assumptions that a certain law is required.

\subsection{Related work}
In the literature, there are some formalizations of stochastic processes. Within Isabelle/HOL, the Kolmogorov extension theorem has been previously formalized \cite{Immler2012}. This formalization only works on Polish spaces (rather than on spaces where every finite measure is inner regular with respect to compact sets, see below), and only in the case where the state spaces for all times are identical. As for the Kolmogorov-Chentson-Theorem (showing continuity of paths), there is an Isabelle/HOL formalization as well \cite{Kolmogorov_Chentsov-AFP}. It uses the index set  $\R_+$ (rather than a more general type) with the usual dyadics proof, as e.g. outlined in \cite{kallenberg2021}. Last,
Brownian motion in implemented in Isabelle/HOL at \cite{laursen2024brownian} (the code is on \href{https://github.com/cplaursen/Brownian_Motion}{github}). As the authors say, dependent type theory would have facilitated their work in places.

For the Lean theorem prover, \cite{ying2023formalization} formalized martingales (see e.g.\ \cite{kallenberg2021}) and was the first implementation of stochastic processes. In our work, however, we do not touch martingales, and rather build on implementations of measure theory, as implemented in \cite{mathlib}. We benefitted from recent efforts to write code and a description of the proofs using the blueprint tool \cite{Monticone_LeanProject_2025}.

\section{The formalization}
Let us start with our notation. Any stochastic process has an index set $\iota$ (usually denoted {\em time}, usually uncountably infinite), and a state space. Since we use dependent type theory, the state space may depend on the time, i.e.\ the state space at time $t$ is $\alpha t$. Probability measures are denoted $P_.$.

All references to results in \lstinline|mathlib| are accurate for commit {\tt xxx}, August 22, 2025.

\subsection{The Carathéodory and Kolmogorov Extension Theorems}
The usual approach to construct (the distribution of) a stochastic process works as follows: describe properties of the distribution of the stochastic process $P_J$ at some arbitrary but finite number of times $J = \{t_1,...,t_n\} \subseteq \iota$.
The resulting family of probability measures $(P_J)_{J \subseteq \iota \text{ finite}}$ has to be {\em projective} in the sense that the projection of $P_J$ to $H\subseteq J$ has to be equal to $P_H$. In other words, when describing the distribution of the stochastic process at all times in $J$, and then forgetting all properties for times in $J\setminus H$, results in the description of properties at times in $H$. One may then ask if this already gives a complete description of the process for all times.

It is the achievement of Kolmogorov that these finite-dimensional distributions in fact provide a unique description of the distribution of a stochastic process, even if $\iota$ is uncountable, as long as the underlying family of state spaces $(\alpha_t)_{t\in\iota}$ is nice enough (Polish, i.e.\ a separable topological space which can be metrized by a complete metric, for example) \cite{kolmogoroff1933grundbegriffe}.
The resulting measure is defined on the product-$\sigma$-field $\mathcal F :=\bigotimes_{t\in\iota} \mathcal B(\alpha_t)$ (where $\mathcal B(\alpha_t)$ is the Borel $\sigma$-algebra on $\alpha_t$). Here, $\mathcal F$ is generated by finite projections and hence any element of $\mathcal F$ may only depend on at most countably many $t\in \iota$, making this a rather coarse $\sigma$-algebra. (In particular, note that this is not the Borel $\sigma$-algebra of the product topology for infinite $\iota$.)

The Kolmogorov extension theorem is on the interface between measure theory and probability theory. Here, we rely on a decent amount of formalized mathematics in the measure-theory part of {\tt mathlib} (outer measures, above all), while not requiring any specific previous formalization of probability theory. (In fact, most of our results are formulated in terms of finite rather than probability measures.)

We are going to formulate the main result in a modern fashion, as e.g.\ found in Theorem 2.2 of \cite{rao1971projective}, Theorem 7.7.1 of Volume~2 of \cite{bogachev2007measure}, Theorem 15.26 of \cite{guide2006infinite}, or \cite{border1998expository}. Note that these formulations split general assumptions on the underlying space(s) (e.g.\ a metric property) from the property which is needed in the proof (inner regularity with respect to compact sets). Other -- highly readable -- references such as \cite{Billingsley1995} state the extension theorem only in special cases such as $\alpha_t = \mathbb R$ for all $t$.


\subsection{Gaussian Measures and characteristic functions}
Our goal in this subsection is to define the finite-dimensional distributions of Brownian Motion. For times $t := (t_1, ..., t_n)$, this is given by the multi-dimensional Gaussian distribution $N(0, C_t)$, where $0$ is the vector of expectations, and $C_t$ is the covariance matrix, given by $C_{ij} = t_i \wedge t_j$. In order to do so, we rely on (i) the implementation of the one-dimensional normal distribution (xxx ref to mathlib) and characteristic functions of probability (or finite) measures.

For any probability measure $P$ on $\mathbb R^n$, its characteristic function is given by $\psi: t \mapsto \int e^{it^\top x} P(dx)$, where the integral takes values in $\mathbb C$. We use the fact that $\psi$ characterizes $P$ uniquely (xxx ref to mathlib). For the standard normal distribution $N(0,1)$ this is $\psi_{N(0,1)}(t) = \exp(-t^2/2)$. Moreover, by independence, we can as well define the $n$-fold product measure $N(0, I_n)$, where $I_n$ is the unit matrix with characteristic function $\psi_{N(0,I_n)}(t) = \exp\big(-\tfrac 12 t^\top I_n t\big)$. In addition, we call a probability measure $P$ on $\R^n$ Gaussian if there is some non-negative definite matrix $C$ with $\psi_P(t) = \exp\big( - \tfrac 12 t^\top C t\big)$. For any such $C$, such a measure exists, since there is $A$ with $C = A^\top A$ (xxx ref to mathlib) and there is the image of $N(0,I_n)$ under the map $f : x\mapsto Ax$. It has the caracteristic function $$\psi_{f_\ast N(0,I_n)}(t) = \int e^{it^\top x} f_\ast N(0,I_n) dx = \int e^{it^\top A x} N(0,I_n) dx = \exp\big( - \tfrac 12 t^\top C t\big).$$ Using the same transformation, we can show that Gaussian measures are closed under linear maps.

So, we can define the finite dimensional distributions of Brownian motion given that we show that $C \in \R^n$ with entries $C_{ij} = t_i \wedge t_j$ is non-negative definite. For this, we rely on Gram matrices, which are based on inner product spaces. In such a space $E$ (with scalar product $\langle .,. \rangle$), and $v_i,...,v_n \in E$, define $C_{ij} := \langle v_i, v_j\rangle$. Then, for $t :=(t_1,...,t_n) \in \R^n$,
$$ t^\top C t = \sum_{i,j} t_i \langle v_i, v_j\rangle t_j = \Big\langle \sum_i t_i v_i, \sum_j t_j v_j\Big\rangle \geq 0.$$
Let $v_i = 1_{[0,t_i]}$ in the space of $L^2$ integrable functions with respect to Lebesgue integral. Then,
$$ \langle v_i, v_j \rangle = \int 1_{[0,t_i]}(x) 1_{[0,t_j]}(x) dx = \int 1_{[0,t_i \wedge t_j]}(x) dx = t_i \wedge t_j.$$
So, $C$ from above is a Gram matrix, which is non-negative definite by general theory, and we have constructed the finite dimensional distributions for Brownian motion.

\cite{hairer2009introduction}

\subsection{The Kolmogorov-Chentsov Theorem}
Let us describe briefly the Kolmogorov-Chentsov Theorem in a simple case here, before we dive deeper in the next sections. The result states that for a stochastic process $X$ (with $\iota = [0,1])$, assume we find $\alpha, \beta, C > 0$ satisfying
\begin{align}
\label{eq:cs}
  \mathbf E[r(X_s, X_t)^\alpha] \leq C|t-s|^{\beta + 1}, \qquad 0\leq s,t\leq 1.
\end{align}
Then there exists $Y = (Y_t)_{t\in [0,1]}$ with $\mathbf P(X_t = Y_t) = 1$ for all $t\in [0,1]$ and $Y$ has almost surely Hölder continuous paths with coefficient $\gamma$ for any $\gamma < \tfrac \beta \alpha$.

In order to see this, set $D_n := \{k/2^n: k=0,...,2^n\}$ and $D := \bigcup_{n\in\mathbb N} D_n$. Start by showing summability of $\mathbf P\Big( \sup_{s,t\in D_n, |t-s| = 2^{-n}} r(X_s, X_t) \geq 2^{-\gamma n} \Big)$ using \eqref{eq:cs}. By the Borel-Cantelli Lemma, this shows that $\sup_{s,t\in D_n, |t-s| = 2^{-n}} r(X_s, X_t) \leq 2^{-\gamma n}$ holds for $n$ large enough. From this, we see that $X$ is locally Hölder-$\gamma$ continuous on $D$. From here, define some Hölder continuous $Y$ coinciding with $X$ on $D$. Finally, fix $t \in [0,1]$ and $t_1, t_2,...\in D$ with $t_n \xrightarrow{n\to\infty} t$. Using \eqref{eq:cs}, we see that $X_{t_n} \xrightarrow{n\to\infty} X_t$ in probability, as well as $Y_{t_n} \xrightarrow{n\to\infty} Y_t$ almost surely due to continuity of $Y$. Therefore, $X_t = Y_t$ almost surely.

We will use a more general version of this statement, replacing $\iota = [0,1]$ by a metric space with a property restricting the number of balls needed to cover $\iota$. This is based on recent work of \cite{talagrand2022upper} and \cite{kratschmer2023kolmogorov}.



\subsection{Construction of Brownian motion and Wiener measure on $\R_+$}
projective property of fdds and an application of Chentsov.


\section{Acknowledgements}
Other contributors, who made one or two PRs: Jonas Bayer, Lorenzo Loccioli, Alessio Rondelli, Jérémy Scanvic

Blueprint: Patrick Massot (citation?)

Project template \cite{Monticone_LeanProject_2025} and technical support: Pietro Monticone

Lean/Mathlib community, Mathlib reviewers (Sébastien Gouëzel in particular?)

\printbibliography

\end{document}

One of the main building blocks of modern probability theory are stochastic processes, which are usually defined as any collection of random variables -- $(X_t)_{t\in \iota}$ with $X_t$ taking values in some $\alpha_t$ for all $t\in\iota$ -- defined on some joint probability space $(\Omega, \mathcal A, \mathbf P)$.  (As usual, we will refer to $\iota$ as the index set of times.) In order to study such processes, it is fundamental to talk about their joint distribution, i.e.\ a probability distribution on the product set $\prod_{t\in\iota} \alpha_t$.









We note that a version of the extension result was proved by Daniell in the 1930s, but this paper was not acknowledged by the probabilists of that time \cite{aldrich2007but}. Due to his contribution, the theorem is often called the {\em Daniell-Kolmogorov extension}.

The goal of our contribution is a formalization of the proof of that theorem in {\tt Lean}. We are using \leanline{Lean4}\cite{moura2021lean} and its mathematical library \leanline{mathlib} \cite{mathlib2020lean}




The main steps in our construction, which were previously missing in {\tt mathlib}, are (more mathematical details are below, and in standard textbooks on Probability Theory, e.g.\ \cite{Klenke2013, Kallenberg2020}):
\begin{enumerate}
\item a formalization of (the set-system of) semi-rings (see
  Definition~\ref{def:semi});
\item a definition of additive contents over semi-rings (see Definition~\ref{def:content});
\item a proof that a single probability measure on a Polish space is inner regular with respect to compact sets (see Definition~\ref{def:innerreg}; in fact, we proved a slight generalization using pseudo-metric spaces, found in Lemma~\ref{L:relcoPol} below);
\item the classical Carathéodory extension theorem, providing us with a candidate for the measure which we want to construct (see Theorem~\ref{T:masseind});
\item the Kolmogorov extension theorem, as based on the previous steps (See Theorem~\ref{T1}).
\end{enumerate}
The Kolmogorov extension theorem has been previously formalized in Isabelle/HOL \cite{Immler2012}. This formalization only works on Polish spaces (rather than on spaces where every finite measure is inner regular with respect to compact sets, see below), and only in the case where all $\alpha_i$'s are identical. %In addition, Isabelle/HOL works with simple type theory, while Lean is an implementation of dependent type theory.

%In addition, there are still new proofs found for the general extension theorem \cite{chin2019new}, but they require some results not yet formalized in mathlib (Borel isomorphism of $\mathbb R$ to $\{0,1\}^{\mathbb N}$), so we do not follow this route.


\begin{definition}[Metric and topological spaces]
  \begin{enumerate}
  \item \sloppy A pseudo-metric on $\alpha$ is a symmetric map $r : \alpha
    \times \alpha \to [0,\infty)$ satisfying the triangle inequality,
      i.e.\ $r(x,z) \leq r(x,y) + r(y,z)$ for all $x,y,z\in\alpha$.
      \\ If $r$ also satisfies $r(x,y) = 0$ iff $x=y$, we call it a
      metric.  \\ If $r : \alpha \times \alpha \to [0,\infty]$
      (i.e.\ $r(x,y) = \infty$ is allowed), we call $r$ an extended
      (pseudo-)metric.
    \item Let $r$ be an (extended pseudo-)metric. A sequence $x_1,
      x_2,... \in \alpha$ is called Cauchy if for all $\varepsilon>0$
      there is $N\in\mathbb N$ such that $r(x_n, x_m) < \varepsilon$
      for all $m,n > N$. The (extended pseudo-) metric is called
      complete if every Cauchy-sequence has a limit in
      $\alpha$.
    \item Some\footnote{We denote by $2^\alpha$ the power set of
      $\alpha$, i.e.\ the set of all subsets of $\alpha$.} $\mathcal O
      \subseteq 2^\alpha$ is called a topology, if it satisfies (i)
      $\emptyset, \alpha \in \mathcal O$, (ii) $\mathcal O$ is a
      $\pi$-system, i.e.\ it is stable under finite intersections,
      i.e.\ if $A, B \in \mathcal O$, then $A \cap B \in \mathcal O$,
      and (iii) $\mathcal O$ is stable under arbitrary unions,
      i.e.\ if $A_i \in \mathcal O$ for all $i\in\iota$ and $\iota$ is
      arbitrary, then $\bigcup_{i\in \iota} A_i \in \mathcal O$.
  \end{enumerate}
\end{definition}

\begin{remark}[Metric and topological spaces in {\tt mathlib}] \label{rem:uniform}\mbox{}
  \begin{enumerate}
    \item \sloppy \leanline{mathlib} provides the class \leanline{PseudoEMetricSpace α},
      which comes with an extended pseudo-distance
      \leanline{edist: α → α → ℝ≥0∞} (the notation \leanline{ℝ≥0∞}
      stands for $[0, \infty]$), and the properties
      \leanline{edist_self} (distance to self is zero),
      \leanline{edist_comm} (commutativity) and
      \leanline{edist_triangle} (triangle inequality).
      That class also comes with \leanline{toUniformSpace} and
      \leanline{uniformity_edist}, defining a uniform space from the
      extended pseudo-metric.
    \item A uniform space (\leanline{UniformSpace α}) does not come with a
      metric, but with a filter on $\alpha \times \alpha$, which
      describes which points in $\alpha$ are near. For example, the
      diagonal of $\alpha \times \alpha$ is a subset of all sets in
      the uniformity; see \cite{james2013topologies} for details. We
      note that a uniform space with a countably generated uniformity
      filter is pseudometrizable, i.e.\ there exists a
      pseudo-metric-space structure that generates the same
      uniformity; see \leanline{UniformSpace.pseudoMetrizableSpace},
      which formalizes a result stated in
      \cite{melikhov2011metrizable}.
    \item \sloppy A topological space is defined in \leanline{mathlib} as \leanline{TopologicalSpace α},
      which comes with a predicate \leanline{IsOpen}, and properties \leanline{isOpen_univ : IsOpen Set.univ}, \leanline{isOpen_inter} and
      \leanline{isOpen_sUnion}, which are exactly the properties of a
      topological space described above.
      A uniform space defines a topology, given by
      \leanline{∀ (s : Set α), IsOpen s ↔ ∀ (x : α), x ∈ s → {p | p.fst = x → p.snd ∈ s} ∈ uniformity}.
%    \item Any (extended pseudo-)metric on $\alpha$ defines a topology,
%      namely the topology generated by $\mathcal H := \{\{y:
%      r(x,y)<\varepsilon\}: x \in \alpha, \varepsilon \in
%      (0,\infty)\}$. Actually, in \leanline{mathlib}, as we have seen
%      above, every extended pseudo-metric defines a uniform space, and
%      a uniform space is a \leanline{class UniformSpace(α : Type u) extends TopologicalSpace, UniformSpace.Core} (where the
%      uniformity is defined in \leanline{UniformSpace.Core}), which
%      connects the \leanline{uniformity} with the topology using
%      \leanline{∀ (s : Set α), IsOpen s ↔ ∀ (x : α), x ∈ s → {p | p.fst = x → p.snd ∈ s} ∈ uniformity}. In particular, a
%      uniform space defines a topological space, which can be used by
%      the typeclass system.
  \end{enumerate}
\end{remark}

\begin{remark}[Generated topology]
  \begin{enumerate}
  \item The intersection of any number of topologies is again a
    topology. For this reason, if $\mathcal H \subseteq 2^\alpha$, we
    define the topology $\mathcal O := \bigcap_{\mathcal F \supseteq
      \mathcal H \text{ topology}} \mathcal F$; see
    \leanline{TopologicalSpace.generateFrom}. This is called the
    topology generated by $\mathcal H$. If $\mathcal H$ is closed
    under finite intersections, we call $\mathcal H$ a basis for
    $\mathcal O$; see \leanline{TopologicalSpace.IsTopologicalBasis}.
  \item \sloppy We call the topology (generated from an extended
    pseudo-metric) separable (see
    \leanline{TopologicalSpace.SeparableSpace}) if there is a
    countable $s \subseteq \iota$ such that $\inf\{r(x,y) : y \in s\}
    = 0$ for all $x\in\alpha$. (More generally, a
    \leanline{TopologicalSpace α} is a \leanline{SeparableSpace} iff
    \leanline{∃ s, Set.Countable s ∧ Dense s}, where the latter means
    \leanline{∀ (x : α), x ∈ closure s}, i.e.\ the space equals its
    own closure.) \\ If there is a countable basis of the topology, it
    is separable; see
    \leanline{TopologicalSpace.SecondCountableTopology.to_separableSpace}.
  \end{enumerate}
\end{remark}

\noindent
Finally, we can introduce measures. A measure is defined on a
$\sigma$-algebra, which we introduce next.

\begin{definition}[$\sigma$-algebras and measures]\label{def:sigma}
  \begin{enumerate}
  \item
    We call $\mathcal F \subseteq 2^\alpha$ a $\sigma$-algebra (on
    $\alpha$) if (i) $\emptyset \in \mathcal F$, (ii) $\mathcal F$ is
    stable under complements, i.e.\ $A \in \mathcal F \Rightarrow A^c
    \in \mathcal F$, (iii) $\mathcal F$ is stable under countable
    unions, i.e.\ $A_1, A_2,... \in \mathcal F \Rightarrow
    \bigcup_{n=1}^\infty A_n \in \mathcal F$. We call $(\alpha,
    \mathcal F)$ a measurable space.
  \item For some $\sigma$-algebra $\mathcal F$ on $\alpha$, a function
    $\mu : \mathcal F \to [0, \infty]$ is called a measure, if (i)
    $\mu(\emptyset) = 0$, (ii) $\mu$ is countably additive, i.e.\ for
    $A_1, A_2,... \in \mathcal F$ pairwise disjoint, we have $\mu\Big(
    \bigcup_{n=1}^\infty A_n\Big) = \sum_{n=1}^\infty \mu(A_n)$. We
    call $(\alpha, \mathcal F, \mu)$ a measure space. \\ In addition,
    $\mu$ is called finite if $\mu(\alpha) < \infty$ and a probability
    measure if $\mu(\alpha)=1$.
  \end{enumerate}
\end{definition}

\begin{remark}[Measur(abl)e spaces in \leanline{mathlib}]
  \begin{enumerate}
  \item \sloppy The class \leanline{MeasurableSpace α} is very similar
    to a topological space in \leanline{mathlib}, since it comes with
    \leanline{MeasurableSet' : Set α → Prop},
    \leanline{measurableSet_empty : MeasurableSet' ∅},
    \leanline{measurableSet_compl : (s : Set α) → MeasurableSet' s → MeasurableSet' sᶜ}, and \leanline{measurableSet_iUnion},
    i.e.\ properties (i)-(iii) from Definition~\ref{def:sigma}.1.
  \item We are using outer measures in our construction. In
    \leanline{mathlib}, this is \leanline{MeasureTheory.OuterMeasure α} which is a structure with a function
    \leanline{measureOf : Set α → ℝ≥0∞} such that \leanline{measureOf ∅ = 0} (i.e.\ the empty set has measure~$0$),
    \leanline{∀ {s₁ s₂ : Set α}, s₁ ⊆ s₂ → measureOf s₁ ≤ measureOf s₂}
    (i.e.\ monotonicity) and \leanline{∀ (s : ℕ → Set α), measureOf (⋃ (i : ℕ), s i) ≤ ∑' (i : ℕ), measureOf (s i)} (which we call
    $\sigma$-subadditivity). \\ Note that an outer measure is defined
    on $2^\alpha$, whereas a measure is only defined on a subset (the
    $\sigma$-algebra of measurable sets).
  \item A measure defined on a type \leanline{α} on which we have a \leanline{MeasurableSpace α} is denoted by the type \leanline{MeasureTheory.Measure α}
    %More precisely\todo{I don't understand why all these details are here. We never use MeasureSpace}: A
    %\leanline{MeasureSpace α} extends a \leanline{MeasurableSpace α}
    %by a \leanline{Measure α} (which is usually called
    %\leanline{volume}). For the measure, we have: \leanline{structure MeasureTheory.Measure α [MeasurableSpace α] extends MeasureTheory.OuterMeasure}.
    %Here $\sigma$-additivity of a
    %\leanline{Measure α} reads
%\begin{minted}[mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
%  m_iUnion : ∀ ⦃f : ℕ → Set α⦄,
%    (∀ (i : ℕ), MeasurableSet (f i)) →
%    Pairwise (Disjoint on f) →
%    ↑toOuterMeasure (⋃ (i : ℕ), f i) =
%    ∑' (i : ℕ), ↑toOuterMeasure (f i)
%\end{minted}
  \end{enumerate}
\end{remark}

\noindent


\begin{remark}[Generated $\sigma$-algebra, image measure]
  We will frequently need two basic results:
  \begin{enumerate}
  \item The intersection of any number of $\sigma$-algebras is again a
    $\sigma$-algebra. For this reason, if $\mathcal H \subseteq
    2^\alpha$, we define the $\sigma$-algebra $\sigma(\mathcal H) :=
    \bigcap_{\mathcal F \supseteq \mathcal H \text{ $\sigma$-algebra}}
    \mathcal F$. This is called the $\sigma$-algebra generated from
    $\mathcal H$; see \leanline{MeasurableSpace.generateFrom}.  \\ In
    particular, if $\mathcal O$ is a topology on $\alpha$, we call
    $\mathcal B := \sigma(\mathcal O)$ the Borel $\sigma$-algebra on
    $\alpha$. In \leanline{mathlib}, this is
\begin{minted}[mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def borel (α : Type u) [TopologicalSpace α] :
    MeasurableSpace α :=
  generateFrom { s : Set α | IsOpen s }
\end{minted}
    In addition, \leanline{mathlib} provides a similar notion, which is
\begin{minted}[mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
class OpensMeasurableSpace (α : Type*)
    [TopologicalSpace α] [h : MeasurableSpace α] :
    Prop where borel_le : borel α ≤ h
\end{minted}
    Here, all open sets are measurable, so the $\sigma$-algebra defining
    \leanline{h} might be larger than the Borel $\sigma$-algebra. We will
    need both notions in our proofs.
  \item Let $(\alpha, \mathcal F)$ and $(\beta, \mathcal G)$ be
    measurable spaces. Some $f : \alpha \to \beta$ is called
    measurable (with respect to $\mathcal F$ and $\mathcal G$) if
    $f^{-1} \mathcal G \subseteq \mathcal F$. In \leanline{mathlib},
    see \leanline{Measurable}.
    %and note that this notion usually comes
    %with some \leanline{m : Measure α} and $f$ is almost everywhere
    %measurable (\leanline{AEMeasurable}) if it coincices with some
    %\leanline{Measurable g}, \leanline{m}-almost everywhere\todo{do we need aemeasurable? could it be omitted for simplicity?}.
    \\ In this
    case, if $\mu$ is a measure on $\mathcal F$, the measure $\nu:
    \mathcal G \to [0, \infty], \nu(B) := \mu (f^{-1}(B))$ is called
    the image (or push-forward) measure of $\mu$ under $f$. We write
    $\nu := f_\ast \mu$; see \leanline{MeasureTheory.Measure.map}.
  \end{enumerate}
\end{remark}

We now come to our contribution.
The extension theorem is a statement about extending a
set-function on a product space to a (finite) measure, where the
product space can come with an arbitrary index set.  The next
definition covers the important concept of a projective family of
measures. In short, we define measures on any finite subset of indices
in a consistent way. Finite sets (of some type \leanline{ι}) are
formalized with \leanline{Finset ι}. % Such a \leanline{Finset} is
defined as a \leanline{Multiset}.
%(a quotient type of the \leanline{List}-type with respect to
%permutations of the list) together with a proof that it contains no
%duplicates\todo{remove this implementation detail?}.

\begin{definition}[Projective family and projective limit] \mbox{}
  \begin{enumerate}
  \item For some set $\iota$, we will write $J\subseteq_f \iota$ if
    $J\subseteq \iota$ and $J$ is finite.
    %We will write $J\subseteq_c \iota$ if $J\subseteq \iota$ and $J$
    %is countable.
  \item Let $\iota$ be some (index) set and $(\alpha_i)_{i\in\iota}$ a
    family of sets. For $J\subseteq \iota$, we denote $\alpha_J :=
    \prod_{j \in J} \alpha_j$ and $\pi_J : \alpha_\iota \to \alpha_J$
    the projection. For $H\subseteq J \subseteq \iota$, we write
    $\pi_H^J$ for the projection $\alpha_J \to \alpha_H$.
  \item Let $\mathcal F_i$ be a $\sigma$-algebra in $\alpha_i$,
    $i\in\iota$. For $J\subseteq_f \iota$, let $\mathcal F_J$ be the
    product-$\sigma$-algebra on $\alpha_J$, and $\mathcal F_\iota$ be
    the $\sigma$-algebra generated by cylinder sets
    $\{\pi_J^{-1}\prod_{j\in J} A_j: J \subseteq_f \iota, A_j \in
    \sigma(E_j), j\in J\}$.
  \item A family $(P_J)_{J\subseteq_f I}$, where $P_J$ is a finite
    measure on $\mathcal F_J$, is called projective if
    $$P_H = (\pi_H^{J})_\ast P_J$$ for all
    $H\subseteq J \subseteq_f I$. (Recall that $A \mapsto
    (\pi_H^{J})_\ast P_J(A) := P_J((\pi_H^{J})^{-1}A)$
    is called the image measure of $P_J$ under $\pi_H^{J}$.)
  \item If, for some projective family $(P_J)_{J\subseteq_f \iota}$,
    there is a finite measure $P_\iota$ on $\mathcal F_\iota$ with
    $P_J = (\pi_J)_\ast P_\iota$ for all $J\subseteq_f \iota$, then we
    call $P_\iota$ projective limit of $(P_J)_{J\subseteq_f \iota}$.
  \end{enumerate}
\end{definition}

In contrast to statements already part of \leanline{mathlib}, in the
sequel we \leanlinecolor{highlight} definitions and statements which
are part of our own code. In the formalization of the above, we use
\leanline{variable {ι : Type*} {α: ι → Type*}}, which fixes the
index set $\iota$ and all spaces $\alpha_t, t\in\iota$ as global
variables.  In Lean, the product space is then \leanline{∀ j : ι, α j}
and the product over a finite subset \leanline{J} of \leanline{ι} is \leanline{∀ j : J, α
  j}.

We formalize the projective property as follows. This definition is not specific to measures but works as long as we have a preorder
(which is the subset relation on \leanline{Finset ι} below).

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def IsProjective [Preorder ι]
    (P : ∀ j : ι, α j) (π : ∀ {i j : ι}, j ≤ i → α i → α j) : Prop :=
    ∀ (i j) (hji : j ≤ i), P j = π hji (P i)
\end{minted}

\noindent
With this, we can define the projective family as follows. The typeclass inference system of
\leanline{Lean} automatically uses the subset relation to generate
\leanline{[Preorder (Finset ι)]} when \leanline{isProjective} is
called.

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def IsProjectiveMeasureFamily
    [∀ i, MeasurableSpace (α i)]
    (P : ∀ J : Finset ι, Measure (∀ j : J, α j)) :
    Prop :=
  IsProjective P (fun I _ hJI μ => μ.map
    fun x : ∀ i : I, α i => fun j => x ⟨j, hJI j.2⟩ :
    ∀ (I J : Finset ι) (_ : J ⊆ I), Measure (∀ i : I, α i)
    → Measure (∀ j : J, α j))
\end{minted}

\noindent
It is worth understanding the precise connection of
\leanlinecolor{isProjective} and
\leanlinecolor{isProjectiveMeasureFamily}. In the latter, the first
variable of \leanlinecolor{isProjective} is the family \leanline{P} of
finite measures for all finite subsets of \leanline{ι}. The second
variable is the functions which maps two sets \leanline{I J : Finset
  ι} and a proof \leanline{hJI} of \leanline{J ⊆ I} together with
\leanline{P I} (which is \leanline{μ} in the statement) to the image
measure on \leanline{J}, which is \leanline{μ.map (fun x : ∀ i : I, α
  i => fun j => x ⟨j, hJI j.2⟩)}.  The function used in that image
measure maps every $(x_i)_{i\in I}$ to $(x_i)_{i\in J}$.
%map defined by the
%\leanline{=>}-notation maps every $(x_i)_{i\in I}$ to a function of
%\leanline{j}, whose type is the subtype {\color{blue}\leanline{j} of}
%\leanline{I}, consisting of a value and a proof of \leanline{J ⊆
%  I}. In other words, this is $(x_j)_{j\in J}$.

\noindent
Now we are ready to formulate the Kolmogorov extension theorem:

\begin{theorem}[Kolmogorov extension]\label{T1}
  For all $t\in\iota$, let $\alpha_t$ be a separable, complete
  pseudo-extended-metric space and $\mathcal F_t$ the Borel
  $\sigma$-algebra generated by its topology. Let $(P_J)_{J\subseteq_f
    \iota}$ be a projective family of finite measures and $P$ be
  defined on $\mathcal A := \bigcup_{J \subseteq_f \iota} \mathcal
  F_J$ given by $P(A) = P_J(\pi_J A)$ for $A\in\mathcal F_J$. Then,
  there is a unique extension of $P$ to $\sigma(\mathcal A)$.
\end{theorem}

Rather than giving the formalization of this theorem, we give the
definition of the resulting measure (which is the projective
limit). We give the formalized proof at the end of this section, since
we first have to provide a formalization of all tools needed in the
proof.

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def projectiveLimitWithWeakestHypotheses
    [∀ i, PseudoEMetricSpace (α i)]
    [∀ i, BorelSpace (α i)]
    [∀ i, SecondCountableTopology (α i)]
    [∀ i, CompleteSpace (α i)] [∀ i, Nonempty (α i)]
    (P : ∀ J : Finset ι, Measure (∀ j : J, α j))
    [∀ i, IsFiniteMeasure (P i)]
    (hP : IsProjectiveMeasureFamily P) :
    Measure (∀ i, α i)
\end{minted}

\noindent
Note that we extend the standard assumption that all $\alpha_t$ are
separable, complete metric spaces (or Polish, i.e.\ separable and
metrizable through a complete metric) to cover the case of extended
pseudo-metric spaces. Such spaces do not satisfy the frequently used
Hausdorff (or t2) property, i.e.\ there can be $x\neq y$ such that all
open balls around $x$ and $y$ overlap.  This generalization was only
possible since underlying results in \leanline{mathlib} were already
provided on the same level of generality.  More precisely,
\leanline{isCompact_iff_totallyBounded_isComplete}, which shows that a
set $A \subseteq \alpha$ is compact iff it is complete and totally
bounded (see note~\ref{note:tot}), requires $\alpha$ to be a uniform
space (Remark~\ref{rem:uniform}, recall that every metric space is
uniform).  We also require the underlying space(s) to be
second-countable (used in the proof of Lemma~\ref{L:relcoPol}).  A
second-countable uniform space can be made into an (extended)
pseudo-metric space (\leanline{UniformSpace.pseudoMetrizableSpace});
see also Remark~\ref{rem:uniform} for some more details.

\subsection{Extending a set function}
In the formulation of Theorem~\ref{T1}, we extend $P$, which is
defined on a union of $\sigma$-algebras. However, unions of
$\sigma$-algebras in general are not $\sigma$-algebras, but they can
be used to define the $\sigma$-algebra generated by the union. So, we
need to extend $P$ to the $\sigma$-algebra generated by $\mathcal
A$. This is exactly what Carathéodory's extension theorem is made
for. In fact, we implemented this result in greater generality than
needed for the proof of the extension theorem. Note that $\mathcal A$
in Theorem~\ref{T1} is a ring of sets (see the next definition)
containing the whole set. (This is sometimes called a field of sets.)
We will work with the weaker semi-ring as introduced next in the
formulation of Carathéodory's extension theorem; see
e.g.\ \cite[Definition~1.9]{Klenke2013}.

\begin{definition}[Semi-ring, ring]\label{def:semi}
  Let $\alpha$ be some set. We call $\mathcal H \subseteq 2^\alpha$ a
  \emph{semi-ring}, if it is (i) a $\pi$-system (i.e.\ closed under
  $\cap$) and (ii) for all $A, B \in\mathcal H$ there is $\mathcal K
  \subseteq_f \mathcal H$ with\footnote{We write $A\uplus B$ for
    $A\cup B$ if $A\cap B=\emptyset$.}  $B\setminus A = \biguplus_{K
    \in \mathcal K} K$.  \\ We call $\mathcal H \subseteq 2^\alpha$ a
  \emph{ring}, if it is closed under $\cup$ and under set-differences.
\end{definition}

\noindent
Any ring is a semi-ring since $A\cap B = A \setminus (A \setminus B)$,
i.e.\ every ring is a $\pi$-system.
We define a semi-ring on a type \leanline{α} as follows:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
structure SetSemiring (C : Set (Set α))
    : Prop where
  empty_mem : ∅ ∈ C
  inter_mem : ∀ (s) (_ : s ∈ C) (t) (_ : t ∈ C), s ∩ t ∈ C
  diff_eq_Union' :
    ∀ (s) (_ : s ∈ C) (t) (_ : t ∈ C),
    ∃ (I : Finset (Set α)) (_h_ss : ↑I ⊆ C)
    (_h_dis : PairwiseDisjoint (I : Set (Set α)) id),
      t \ s = ⋃₀ I
\end{minted}

Let us remark that (i) \leanline{Lean} indicates a coercion by
\leanline{↑}, which in this case is from \leanline{Finset} to
\leanline{Set} and (ii) we have \leanline{PairwiseDisjoint (s : Set ι) (f : ι → α)}
iff the images of any distinct elements of \leanline{ι}
under \leanline{f} are different. (Hence, if \leanline{f = id}, the
usual definition of pairwise disjoint sets unfolds.)

\noindent
We do not show the formalization of rings here.
The important ring of sets in our formalization is the ring of measurable cylinders on a product space.
A cylinder is defined as follows:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def cylinder
    (s : Finset ι) (S : Set (∀ i : s, α i)) :
    Set (∀ i : ι, α i) :=
  (fun (f : ∀ j : ι, α j) => fun i : s => f i) ⁻¹' S
\end{minted}

\noindent
In this definition, \leanline{s} is a finite subset of the index set
\leanline{ι}, and for some $S$ in the finite product $\prod_{i \in s}
\alpha_i$, consider the projection $\pi_s : \prod_{i \in \iota}
\alpha_i \to \prod_{i \in s} \alpha_i$, and consider the preimage of
$S$ (This is what the last line in previous definition gives.).
We can define \leanlinecolor{cylinders α}, the set of all measurable cylinders.

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def cylinders : Set (Set (∀ i : ι, α i)) :=
  ⋃ (s) (S) (_ : MeasurableSet S), {cylinder s S}
\end{minted}

\noindent
Membership of that set is characterized as follows:
\begin{minted}[highlightlines={1}, framesep = 0pt, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem mem_cylinders
    (t : Set (∀ i : ι, α i)) :
    t ∈ cylinders α ↔
      ∃ (s S : _) (_ : MeasurableSet S), t = cylinder s S
\end{minted}
\noindent
The finite set \leanline{s} of the potential coordinates where
the cylinder deviates from the whole set need not be unique.
From the $\exists$-statement of \leanline{mem_cylinders}, we however choose an
arbitrary such \leanline{Finset ι}, called \leanlinecolor{cylinders.finset}.


The set-system of cylinders is in fact a field, hence a ring and
a semi-ring. This means we can prove the following:

\begin{minted}[highlightlines={1-4}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem setField_cylinders : SetField (cylinders α)
theorem setRing_cylinders :  SetRing (cylinders α)
theorem setSemiringCylinders
  : SetSemiring (cylinders α)
\end{minted}

From the field/ring/semi-ring of cylinders, we have to define the
generated $\sigma$-algebra. This uses the following:
\begin{minted}[highlightlines={1}, framesep = 0pt, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem generateFrom_cylinders :
    MeasurableSpace.generateFrom (cylinders α)
    = MeasurableSpace.pi

instance MeasurableSpace.pi
    [m : ∀ a, MeasurableSpace (π a)] :
    MeasurableSpace (∀ a, π a) :=
  iSup a, (m a).comap fun b => b a
\end{minted}
Here, \leanline{comap {β : Type} (f : α → β) (m : MeasurableSpace β)}
is the measurable space consisting of pre-images of measurable subsets
of \leanline{β}, and the set of $\sigma$-algebras on the product
$\prod_{i\in\iota} \alpha_i$ (or on any other space) is a complete
lattice, i.e.\ the subset defined by the \leanline{comap}s has a
supremum, which defines the $\sigma$-algebra generated by the
cylinders.

Let us state an important lemma on semi-rings:

\begin{lemma}\label{l1}
  Let $\mathcal H$ be a semi-ring, $\mathcal I \subseteq_f \mathcal H$,
  $A \in \mathcal H$. Then, there is $\mathcal K \subseteq_f \mathcal
  H$ such that $\mathcal K$ contains pairwise disjoint sets and $A
  \setminus \bigcup_{I \in \mathcal I} I = \biguplus_{K\in \mathcal K}
  K$.
\end{lemma}

\begin{proof}
  We proceed by induction on $\mathcal I$. If $\mathcal I$ is a
  singleton, the assertion is true by the definition of a semi-ring. If
  it holds for some $\mathcal I$ (i.e.\ there is $\mathcal K
  \subseteq_f \mathcal H$ with $A \setminus \bigcup_{I \in \mathcal I}
  I = \biguplus_{K\in \mathcal K} K$), let us consider $\mathcal I' =
  \{J\} \cup \mathcal I$ for some $J \notin \mathcal I$. For each $K
  \in \mathcal K$, Write $K \setminus J = \biguplus_{J_K \in \mathcal
    J_K} J_K$ for some $\mathcal J_K \subseteq_f \mathcal H$ (which
  exists by the definition of a semi-ring). Then, write
  \begin{align*}
    A \setminus \bigcup_{I' \in \mathcal I'} I & = \Big(A \setminus
    \bigcup_{I \in \mathcal I} I\Big) \setminus J = \biguplus_{K\in
      \mathcal K} K \setminus J = \biguplus_{K\in \mathcal K}
    \biguplus_{J_K \in \mathcal J_K} J_K.
  \end{align*}
  This concludes the proof, since the latter disjoint union is over a
  finite set.
\end{proof}

The proof as well as its formalization is somewhat straight-forward,
but requires induction over finite sets.

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem exists_disjoint_finset_diff_eq
    (hC : SetSemiring C) (hs : s ∈ C)
    (I : Finset (Set α)) (hI : ↑I ⊆ C) :
    ∃ (J : Finset (Set α)) (_h_ss : ↑J ⊆ C)
    (_h_dis : PairwiseDisjoint (J : Set (Set α)) id),
    s \ ⋃₀ I = ⋃₀ J
\end{minted}

\noindent
The existence-statement of the above lemma actually gives rise to a
definition. Here, we use \leanline{Exists.choose} in order to extract
an element from an $\exists$-statement. In addition, we do not allow
$\emptyset \in \mathcal K$ without loss of generality:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def diff₀ (hC : SetSemiring C)
    (hs : s ∈ C) (I : Finset (Set α)) (hI : ↑I ⊆ C)
    [DecidableEq (Set α)] : Finset (Set α) :=
  (hC.exists_disjoint_finset_diff_eq hs I hI).choose \ {∅}
\end{minted}

\noindent
Extending Lemma~\ref{l1}, we would like to write a finite union of
members of a semi-ring as a finite union of disjoint sets.


\begin{lemma}\label{l2}
  Let $\mathcal H$ be a semi-ring and $A_1,...,A_m \in \mathcal
  H$. Then, there are $\mathcal K_1,...,\mathcal K_m \subseteq_f
  \mathcal H$ disjoint such that $\bigcup_{n=1}^m \mathcal K_n$
  contains disjoint sets and $\bigcup_{m=1}^n A_m = \biguplus_{m=1}^n
  \biguplus_{K \in \mathcal K_n} K$.
\end{lemma}

\begin{proof}
  Indeed, we may write $ \bigcup_{m=1}^n A_m = \biguplus_{n=1}^m
  \Big(A_n \setminus \bigcup_{i=1}^{n-1}A_i\Big).$ Then, the result
  follows by applying Lemma~\ref{l1} to $A_n \setminus
  \bigcup_{i=1}^{n-1}A_i$, $n=1,...,m$.
\end{proof}

%% \noindent
%% The formalized version again gives rise to a definition:

%% \begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
%% def indexedDiff₀ (hC : SetSemiring C)
%%     (J : Finset (Set α)) (hJ : ↑J ⊆ C)
%%     (n : Fin J.card) : Finset (Set α) :=
%%   hC.diff₀ (ordered_mem' hJ n) (finsetLT J n)
%%     (finsetLT_subset' J hJ n)
%% \end{minted}

%% Here, recall that \leanline{Fin n} is the subtype of \leanline{Nat}
%% consisting of all numbers \leanline{<n}. In addition,
%% \leanline{ordered_mem' (hJ : ↑J ⊆ C) (n : Fin (card J)) : ↑(ordered J)
%%   n ∈ C} gives a proof that the \leanline{n}th element of \leanline{J}
%% is in \leanline{C}, \leanline{finsetLT (J : Finset (Set α)) (n : Fin (card J)) : Finset (Set α)} is the set consisting of the
%% \leanline{n} sets in \leanline{J} numbered $0,...,n-1$, and
%% \leanlinecolor{finsetLT_subset'} gives a proof that
%% \leanline{↑(finsetLT J n) ⊆ C}.  So, in terms of Lemma~\ref{l2}, this
%% gives, for $n=1,...,m$, a construction for $\mathcal K_n \subseteq_f
%% \mathcal H$.

\noindent
\subsection{Carathéodory's extension theorem}
Measures are set functions defined on a $\sigma$-algebra, satisfying
some properties which we recall below. Frequently,
constructively defining such a measure on the full $\sigma$-algebra
is not possible, but defining a set function on a semi-ring is
possible. As an example, consider Lebesgue-measure on $\mathbb R$,
with the Borel $\sigma$-algebra on $\mathbb R$, which is
$\sigma(\mathcal O)$, where $\mathcal O$ is the set of open sets, and
$\sigma(\mathcal O)$ is the smallest $\sigma$-algebra containing all
open sets. Since this set system is defined only abstractly, it is
hard to know which volume each of these sets should be assigned to at
first sight. However, the volume of an interval is easy, since it may
be defined by the length of the interval. So, in order to construct
measures from a set function $m$ on a (semi-)ring $\mathcal H$
(e.g.\ the set of all semi-open intervals), it has been a fundamental
insight of Carathéodory that one may start by defining a set function
(outer measure) $\mu$ on $2^\alpha$, and then show $\mu$ extends $m$
and defines a measure on the $\sigma$-algebra of
  measurable sets (see Theorem~\ref{T:cara} below), which contains
$\sigma(\mathcal H)$.
%(Note that the set of semi-open intervals
%generates the Borel $\sigma$-algebra on $\mathbb R$.)
We will follow this abstract construction, and start by stating some
basic concepts.

\begin{definition}\label{def:content}
  For some set $\alpha$, let $\mathcal H \subseteq 2^\alpha$
  and call any $m : \mathcal H \to [0,\infty]$ a
    content.
  \begin{enumerate}
  \item $m$ is called additive if for $\mathcal K \subseteq_f \mathcal
    H$ pairwise disjoint and $\bigcup_{K \in \mathcal K} K \in
    \mathcal H$, we have $m \Big(\bigcup_{K \in \mathcal K} K \Big) =
    \sum_{K \in \mathcal K} m(K)$. If the same holds for\footnote {We
      write $A \subseteq_c B$ if $A$ is a countable subset of
      $B$.}$\mathcal K \subseteq_c \mathcal H$ pairwise disjoint, we
    say that $m$ is $\sigma$-additive.
  \item The set-function $m$ is called sub-additive if for $\mathcal K
    \subseteq_f \mathcal H$ and $\bigcup_{K \in \mathcal K} K \in
    \mathcal H$, we have $m \Big(\bigcup_{K \in \mathcal K} K \Big)
    \leq \sum_{K \in \mathcal K} m(K)$. (Note that elements of
    $\mathcal K$ need not be disjoint.) Here, $\sigma$-sub-additivity
    is defined in the obvious way using $\mathcal K\subseteq_c
    \mathcal H$.
  \item If $m(A) \leq m(B)$ for $A\subseteq B$ and $A,B\in\mathcal H$,
    we say that $m$ is monotone.
  \item If $\mathcal H$ is a $\sigma$-algebra and $m$ is
    $\sigma$-additive with $m(\emptyset) = 0$, we call
    $m$ a measure.
  \item If $\mathcal H = 2^\alpha$ and $m$ is monotone and
    $\sigma$-sub-additive with $m(\emptyset)=0$, we call $m$ an outer
    measure.
  \end{enumerate}
\end{definition}

\noindent
For additive contents, we need two definitions.
The structure \leanlinecolor{AddContent} defines
an additive set-function on \leanline{Set α}.
The definition \leanlinecolor{extendContent} takes an additive function defined only on a semi-ring of sets, and extends it to an additive content on all sets by choosing the value infinity outside of the semi-ring. We use this because total functions are easier to use in subsequent code.

\begin{minted}[highlightlines={1, 10}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
structure AddContent (C : Set (Set α)) where
  toFun : Set α → ℝ≥0∞
  empty' : toFun ∅ = 0
  add' : ∀ (I : Finset (Set α))
    (_h_ss : ↑I ⊆ C) (_h_dis : PairwiseDisjoint
      (I : Set (Set α)) id)
    (_h_mem : ⋃₀ ↑I ∈ C),
    toFun (⋃₀ I) = ∑ u in I, toFun u

def extendContent
    (hC : SetSemiring C)
    (m : ∀ s : Set α, s ∈ C → ℝ≥0∞)
    (m_empty : m ∅ hC.empty_mem = 0)
    (m_add :
      ∀ (I : Finset (Set α)) (h_ss : ↑I ⊆ C)
      (_h_dis : PairwiseDisjoint (I : Set (Set α)) id)
      (h_mem : ⋃₀ ↑I ∈ C),
      m (⋃₀ I) h_mem = ∑ u : I, m u (h_ss u.prop)) :
    AddContent C
\end{minted}

For the concrete application we have in mind, we introduce a
definition which uses a specific semi-ring, the measurable cylinders,
based on a projective family of measures.  That is the goal of the two
definitions \leanlinecolor{kolmogorovFun} and
\leanlinecolor{kolContent} below:

\begin{minted}[highlightlines={1,7}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def kolmogorovFun
    (P : ∀ J : Finset ι, Measure (∀ j : J, α j))
    (s : Set (∀ i, α i))
    (hs : s ∈ cylinders α) : ℝ≥0∞ :=
  P (cylinders.finset hs) (cylinders.set hs)

def kolContent
    (hP : IsProjectiveMeasureFamily P) :
    AddContent (cylinders α) :=
  extendContent setSemiringCylinders
    (kolmogorovFun P) (kolmogorovFun_empty hP)
    (kolmogorovFun_additive hP)
\end{minted}

Here, \leanlinecolor{kolmogorovFun_empty} and
\leanlinecolor{kolmogorovFun_⌋} \leanlinecolor{additive} give proofs for
\leanline{m_empty} and \leanline{m_add} in
\leanlinecolor{extendContent} as applied to a
\leanlinecolor{kolmogorovFun}.

\noindent
From the next lemma, we will need monotonicity and sub-additivity, as
well as $\sigma$-additive $\Rightarrow$ $\sigma$-sub-additive in the
proof of the Carathéodory extension,
Theorem~\ref{T:masseind}. We do not show any details
  about its formalization here.

\begin{lemma}[Set-functions on semi-rings]\label{l:halbextRing}
  Let $\mathcal H$ be a semi-ring and $m: \mathcal H\to [0,\infty]$
  additive. Then, $m$ is monotone and sub-additive. In addition, $m$
  is $\sigma$-additive iff it is $\sigma$-sub-additive.
\end{lemma}

\begin{proof}
  We start by monotonicity. Let $A, B\in\mathcal H$ with $A\subseteq
  B$ and $\mathcal K \subseteq_f \mathcal H$ with $B \setminus A =
  \biguplus_{K\in\mathcal K} K$. Therefore, we can write $m(A) \leq
  m(A) + \sum_{K\in\mathcal K} m(K) = m(B)$.

  Next, we claim that for $\biguplus_{I\in\mathcal I} I \subseteq A$
  with all sets belonging to $\mathcal H$, we have $\sum_{I \in \mathcal
    I} m(I) \leq m(A)$. For this, write $A \setminus \biguplus_{I\in
    \mathcal I} I = \biguplus_{K\in\mathcal K} K$ as in
  Lemma~\ref{l1}. Then,
  $$ m(A) = m\Big(\biguplus_{I\in\mathcal I} I \uplus
  \biguplus_{K\in\mathcal K} K\Big) = \sum_{I\in\mathcal I} m(I) +
  \sum_{K\in\mathcal K} m(K) \geq \sum_{I\in\mathcal I} m(I). $$

  For sub-additivity, let $\mathcal I \subseteq_f \mathcal H$ with
  $\bigcup_{I \in \mathcal I} I \in \mathcal H$. Without loss of
  generality, we write $\mathcal I = \{I_1,...,I_n\}$ for some $n$. We
  need to show $m\Big(\bigcup_{k=1}^n I_i\Big) \leq \sum_{k=1}^n
  m(I_k)$. For $k=2,...,n$, we write
  $$ \bigcup_{k=1}^n I_k = \biguplus_{k=1}^n \Big(I_k \setminus
  \bigcup_{j=1}^{k-1} I_j\Big) = \biguplus_{k=1}^n \biguplus_{K_k \in
    \mathcal K_k} K_k$$ with $\mathcal K_k$ as in Lemma~\ref{l1}. So,
  since $\biguplus_{K_k \in \mathcal K_k} K_k \subseteq I_k \in
  \mathcal H$,
  $$ m\Big(\bigcup_{k=1}^n I_i\Big) = \sum_{k=1}^n \sum_{K_k \in
    \mathcal K_k} m(K_k) \leq \sum_{k=1}^n m(I_k).$$

  \noindent
  Now, we show that $m$ is $\sigma$-additive $\iff$ it is
  $\sigma$-sub-additive.

  \noindent
  '$\Rightarrow$': Here, just copy the proof of sub-additivity, but
  using countable $\mathcal I$, i.e.\ $n=\infty$. For '$\Leftarrow$',
  let $\mathcal I \subseteq_c \mathcal H$ and consist of
  disjoint sets with $A = \biguplus_{I \in \mathcal I} I \in\mathcal
  H$. Since $m$ is monotone and for any $\mathcal I' \subseteq_f
  \mathcal I$, we have $\biguplus_{I\in\mathcal I'} I \subseteq A$
  (hence $\sum_{I \in \mathcal I'} m(I') \leq m(A)$),
  $$ \sum_{I \in \mathcal I} m(I) = \sup_{\mathcal I' \subseteq_f
    \mathcal I} \sum_{I \in \mathcal I'} m(I) \leq m(A) \leq \sum_{I
    \in \mathcal I} m(I)$$ by $\sigma$-sub-additivity. So,
  $\sigma$-additivity follows.
\end{proof}

\noindent
Although some material on outer measures was covered in {\tt mathlib}
already, the classical extension theorem (extending a set function $m$
on a semi-ring $\mathcal H$)) was not provided yet. In particular, this
result states that the outer measure coincides with $m$ on $\mathcal
H$. All statements on equality of $\mu$ and $m$ present in {\tt
  mathlib} at the time of writing have too many requirements: they all require $m$ to be a $\sigma$-additive function defined on a $\sigma$-algebra.

The next result extends a set function on a semi-ring to an outer measure.

\begin{proposition}[Outer measure induced by a set function on a semi-ring] %\mbox{}
  Let \label{P:auss} $\mathcal H$ be a semi-ring and $m: \mathcal
  H\to\mathbb R_+$ additive. For $A\subseteq E$ let
  $$ \mu(A) := \inf_{\mathcal G \in \mathcal U(A)}
    \sum_{G\in\mathcal G} m(G)$$ where
  $$ \mathcal U(A) := \big\{\mathcal G \subseteq_c \mathcal H,
    A\subseteq \bigcup_{G\in\mathcal G} G\big\}$$ is the set of
    countable coverings of $A$. Then, $\mu$ is an outer measure.
\end{proposition}

\sloppy Let us now formulate the classical results by
Carathéodory. The first leads to the definition of the measurable
space \leanline{OuterMeasure.caratheodory}, covered in
\leanline{mathlib}. See e.g.\ \cite[Theorem 2.1]{Kallenberg2020}

\begin{theorem}[\boldmath $\mu$-measurable sets are a
    $\sigma$-algebra]\label{T:cara} Let $\mu$ be an outer measure on
  $E$ and $\mathcal F$ the set of $\mu$-measurable sets,
  i.e.\ the set of sets $A$ satisfying
  \begin{align*}
    \mu(B) = \mu(B\cap A) + \mu(B\cap A^c), \qquad B \subseteq E.
  \end{align*}
  Then, $\mathcal F$ is a $\sigma$-Algebra and $\mu|_{\mathcal F}$ is
  a measure. In addition, $\{N\subseteq \Omega:
  \mu(N)=0\}\subseteq \mathcal F$, i.e.\ $\mathcal F$ is complete.
\end{theorem}

\noindent
\sloppy The second result states that for an outer measure induced by
an additive content on a semi-ring, we have $\sigma(\mathcal H)
\subseteq \mathcal F$. In particular, we then have defined a measure
on $\sigma(\mathcal H)$. This result is not yet covered in {\tt
  mathlib}. However, for product spaces, in
\leanline{MeasureTheory.Constructions.Pi}, there is
\leanline{pi_caratheodory}, which shows that $\sigma(\mathcal H)
\subseteq \mathcal F$ in the construction of a product
  measure for a finite index set. In addition, there is
\leanline{pi_pi_aux}, which shows that $\mu$ extends $m$ on $\mathcal
H$ in the same special case. See also \cite[Theorem
  2.5]{Kallenberg2020}.

\begin{theorem}[Carathéodory extension]\label{T:masseind}
  Let $\mathcal H$ be a semi-ring and $m: \mathcal H\to\mathbb R_+$
  $\sigma$-finite and $\sigma$-additive. Furthermore, let $\mu$ be the
  induced outer measure from Proposition~\ref{P:auss} and $\mathcal F$
  the $\sigma$-algebra from Theorem~\ref{T:cara}. Then,
  $\sigma(\mathcal H)\subseteq\mathcal F$ and $\mu$ coincides with $m$
  on $\mathcal H$.
\end{theorem}

\begin{proof}
  First, $m$ is $\sigma$-sub-additive by
  Lemma~\ref{l:halbextRing}.

  ~

  \noindent\emph{Step 1: $\mu|_{\mathcal H} = m$:} Let $A\in\mathcal
  H$. Choose $\mathcal K \subseteq_c \mathcal H$ with
  $A\subseteq \bigcup_{K\in\mathcal K} K$ and
  $$\mu(A) \geq \sum_{K\in\mathcal K} m(K) - \varepsilon.$$ By $ A =
  \bigcup_{K\in\mathcal K} K\cap A$,
  \begin{align*}
    \mu(A) \leq m(A) \leq \sum_{K\in\mathcal K} m(K\cap A) \leq
    \sum_{K\in\mathcal K} m(K) \leq \mu(A) + \varepsilon,
  \end{align*}
  where we have used $\sigma$-sub-additivity of $m$ in the second and
  monotonicity of $m$ in the third $\leq$ (see
  Lemma~\ref{l:halbextRing}).  With $\varepsilon\to 0$ we find that
  $\mu(A) = m(A)$.

  ~

  \noindent\emph{Step 2: $\sigma(\mathcal H)\subseteq \mathcal F$:}
  Let $B \subseteq E$, $A\in\mathcal H$ and $\varepsilon>0$. Choose
  $\mathcal K \subseteq_c \mathcal H$ such that $B \subseteq
  \bigcup_{K \in \mathcal K} K$ and $\mu(B) \geq \sum_{K\in\mathcal K}
  m(K) - \varepsilon.$ Then, by additivity of $m$,
  \begin{align*}
    \mu(B)+\varepsilon & \geq \sum_{K\in\mathcal K} \mu(K) =
    \sum_{K\in\mathcal K} \mu(K\cap A) + \sum_{K\in\mathcal K}
    \mu(K\cap A^c) \\ & \geq \mu(B\cap A) + \mu(B\cap A^c).
  \end{align*}
  By sub-additivity of $\mu$, we find that $\mu(B) \leq \mu(B\cap A) +
  \mu(B \cap A)$, so letting $\varepsilon\to 0$ leads to $\mu(A) =
  \mu(E\cap A) + \mu(E\cap A^c)$. This implies that $A$ is $\mathcal
  F$-measurable, and we have shown $\sigma(\mathcal H) \subseteq
  \mathcal F$, since $\mathcal F$ is a $\sigma$-algebra.
\end{proof}

\noindent
Here is a formalization of the measure resulting from
Theorem~\ref{T:masseind}:

%% \begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
%% def ofAddSubaddCaratheodory
%%     (hC : SetSemiring C)
%%     (m : ∀ s : Set α, s ∈ C → ℝ≥0∞)
%%     (m_empty : m ∅ hC.empty_mem = 0)
%%     (m_add : ∀ (I : Finset (Set α)) (h_ss : ↑I ⊆ C)
%%       (_h_dis : PairwiseDisjoint (I : Set (Set α)) id)
%%       (h_mem : ⋃₀ ↑I ∈ C),
%%       m (⋃₀ I) h_mem = ∑ u : I, m u (h_ss u.prop))
%%     (m_sigma_subadd : ∀ ⦃f : ℕ → Set α⦄
%%       (hf : ∀ i, f i ∈ C) (hf_Union : (⋃ i, f i) ∈ C),
%%       m (⋃ i, f i) hf_Union ≤ ∑' i, m (f i) (hf i)) :
%%     @Measure α (inducedOuterMeasure m
%%       hC.empty_mem m_empty).caratheodory
%% \end{minted}


%% \noindent
%% Here, \leanline{MeasureTheory.OuterMeasure.caratheodory}\todo{used in
%%   dot notation... but we don't want to explain this} is already
%% implemented and gives the assertion that $\mathcal F$ from
%% Theorem~\ref{T:cara} is a $\sigma$-algebra. Note that
%% \leanline{@Measure} is the same as \leanline{Measure}, but all
%% variables have to be given explicitely. The second argument is a proof
%% that measurable sets form a $\sigma$-algebra which cannot be inferred
%% by the type class system of \leanline{Lean}.

%% \noindent
%% In the proof of Kolmogorov's extension theorem, we use a closely
%% related definition\todo{should we present only this one and omit the lemma above?}:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def Measure.ofAddContent
    [mα : MeasurableSpace α] (hC : SetSemiring C)
    (hC_gen : MeasurableSpace.generateFrom C = mα)
    (m : AddContent C)
    (m_sigma_subadd : ∀ ⦃f : ℕ → Set α⦄
      (hf : ∀ i, f i ∈ C) (hf_Union : (⋃ i, f i) ∈ C),
      m (⋃ i, f i) hf_Union ≤ ∑' i, m (f i) (hf i)) :
    Measure α
\end{minted}

\subsection{$\sigma$-additivity of set functions}
For the proof of Kolmogorov's extension Theorem, note that $P$ as
given in Theorem~\ref{T1} is a finite additive set function on the
ring $\mathcal A$. In order to use Theorem~\ref{T:masseind}, we
therefore have to show $\sigma$-additivity. For this, we will use
Lemma~\ref{l:stetigcompact} below, i.e.\ inner regularity of $P$ with
respect to compact sets. Before, we will show useful alternative
conditions for $\sigma$-additivity, which do not make use of any
topological structure of the underlying space.

\begin{lemma}[$\sigma$-additivity and continuity at $\emptyset$]\label{P:stetigmass}
  Let $\mathcal R$ be a ring and $m:\mathcal R\to \mathbb R_+$
  additive. Then, the following are equivalent:
  \begin{enumerate}
    \item $m$ is $\sigma$-additive;
    \item $m$ is $\sigma$-sub-additive;
    \item $m$ is continuous from below, i.e.\ for $A, A_1, A_2,... \in
      \mathcal R$ with $A_1 \subseteq A_2 \subseteq \cdots$ and $A =
      \bigcup_{n=1}^\infty A_n$, we have $m(A) = \lim_{n\to\infty}
      m(A_n)$.
    \item $m$ is continuous from above in $\emptyset$, i.e.\ for $A_1,
      A_2,...\in\mathcal R$ with $A_1 \supseteq A_2 \supseteq ...$ and
      $\bigcap_{n=1}^\infty A_n = \emptyset$, we have
      $\lim_{n\to\infty} m(A_n)=0$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  1.$\Leftrightarrow$2.\ was already shown in
  Lemma~\ref{l:halbextRing}, since $\mathcal R$ is a semi-ring.

  ~

  \noindent 1.$\Rightarrow$3.: For $A_1, A_2,...$ as in 3., we write
  (with $A_0 := \emptyset$)
  \begin{align*}
     m(A) & % = m\Big( \biguplus_{n=1}^\infty \Big(A_n \setminus
     %\Big(\bigcup_{l=1}^{k-1} A_l\Big)\Big)\Big)
     = \lim_{n\to\infty}
     m\Big( \biguplus_{k=1}^n A_k \setminus \Big(\Big(\bigcup_{l=1}^{k-1}
     A_l\Big)\Big)\Big) = \lim_{n\to\infty} m(A_n).
  \end{align*}

  \noindent 3.$\Rightarrow$1.: Let $A_1, A_2,... \in \mathcal R$ be
  disjoint and $A = \biguplus_{n=1}^\infty A_n$. Set $B_n :=
  \bigcup_{k=1}^n A_k$, such that $B_1, B_2,...$ satisfy 3. Hence,
  \begin{align*}
    m\Big( \biguplus_{n=1}^\infty A_n\Big) & = m\Big(
    \bigcup_{n=1}^\infty B_n\Big) = \lim_{n\to\infty} m\Big(
    \bigcup_{k=1}^n B_n\Big) \\ & = \lim_{n\to\infty} m\Big(
    \biguplus_{k=1}^n A_n\Big) = \sum_{n=1}^\infty m(A_n).
  \end{align*}

  \noindent 3.$\Rightarrow$4.: Let $A_1, A_2,\dots \in\mathcal R$ as
  in 4. Set $B_n := A_1\setminus A_n$. Then, $B=A_1,B_1,B_2,\dots
  \in\mathcal R$ satisfy 3., and therefore
  $$m(A_1) = \lim_{n\to\infty} m(B_n) = m(A_1) -
  \lim_{n\to\infty}m(A_n),$$ and 4.\ follows.

  ~

  \noindent 4.$\Rightarrow$3.: Let $A,A_1,A_2,\dots \in\mathcal R$ as
  in 3. Let $B_n := A\setminus A_n \in \mathcal R, n\in\mathbb
  N$. Then, $\bigcap_{n=1}^\infty B_n = \emptyset$, so $$0 =
  \lim_{n\to\infty} \mu(B_n) = \mu(A) - \lim_{n\to\infty} \mu(A_n),$$
  and 3.\ follows.
\end{proof}

\noindent
As an example, we give the formalization of $4.\Rightarrow 1.$:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem sigma_additive_addContent_of_tendsto_zero
    (hC : SetRing C)
    (m : AddContent C)
    (hm_ne_top : ∀ {s} (_ : s ∈ C), m s ≠ ∞)
    (hm : ∀ ⦃s : ℕ → Set α⦄ (_ : ∀ n, s n ∈ C),
      Antitone s → (⋂ n, s n) = ∅ →
      Tendsto (fun n => m (s n)) atTop (nhds 0))
      ⦃f : ℕ → Set α⦄ (hf : ∀ i, f i ∈ C) (hUf : (⋃ i, f i) ∈ C)
      (h_disj : Pairwise (Disjoint on f)) :
    m (⋃ i, f i) = ∑' i, m (f i)
\end{minted}

\noindent
Next, we will be extending our analysis to the case of a topological
space. We define inner (and outer) regularity of set functions.

\begin{definition}[Inner regularity] \label{def:innerreg}
  Let $\alpha$ be some set, equipped with a topology, and $m$ be a
  set-function on some $\mathcal H \subseteq 2^\alpha$.
  \begin{enumerate}
  \item Let $p, q : 2^\alpha \to \{\text{true, false}\}$. Then, $m$ is
    called inner regular with respect to $p$ and $q$, if
    $$ m(A) = \sup\{m(F) : p(F) = \text{true}, F \subseteq A\}$$ for
    all $A \in \mathcal H$ with $q(A) = \text{true}$.
  \item If $q(A) = \text{true}$ iff $A$ is measurable, we neglect the
    {\em and $q$}. If $p(A) = \text{true}$ iff $A$ is closed (compact,
    closed and compact), we say that $m$ is inner regular with respect
    to closed (compact, compact and closed) sets.
  \end{enumerate}
\end{definition}

\noindent
The above definition closely resembles its formalization in
\leanline{mathlib}:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def MeasureTheory.Measure.InnerRegular
    {α : Type u_1}  {_ : MeasurableSpace α}
    (μ : Measure α) (p q : Set α → Prop) :=
  ∀ ⦃U⦄, q U → ∀ r < μ U, ∃ K, K ⊆ U ∧ p K ∧ r < μ K
\end{minted}

For the next result, recall that for compact sets $C_1, C_2,...$ with
$\bigcap_{n=1}^\infty C_n = \emptyset$, there is some $N$ with
$\bigcap_{n=1}^N C_n = \emptyset$. More generally, compact sets form a
compact system, which is defined as follows:

\begin{definition}
  Let $\mathcal C \subseteq 2^\alpha$. If, for all $C_1, C_2,...$ with
  $\bigcap_{n=1}^\infty C_n = \emptyset$, there is some $N$ with
  $\bigcap_{n=1}^N C_n = \emptyset$, we call $\mathcal C$ a {\em
    compact system}.
\end{definition}

\noindent
Here is the formalization:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def IsCompactSystem (p : Set α → Prop) : Prop :=
    ∀ C : ℕ → Set α, (∀ i, p (C i)) → ⋂ i, C i = ∅ →
    ∃ (s : Finset ℕ), ⋂ i ∈ s, C i = ∅
\end{minted}

\noindent
Such compact systems are important since they allow a
proof of $\sigma$-additivity of a content on a ring, which is the
missing piece for applying the Carathéodory Theorem in the proof of
the Kolmogorov extension theorem.

\begin{lemma}\label{l:stetigcompact}
  Let $\alpha$ be a topological space and $\mu$ be an additive set
  function on a ring $\mathcal R$ contained by the Borel
  $\sigma$-algebra, and which is inner regular with respect to a
  compact system. Then, $\mu$ is $\sigma$-additive.
\end{lemma}

\begin{proof}
  According to Lemma~\ref{P:stetigmass}, we need to show continuity of
  $\mu$ in $\emptyset$, so let $A_1 \supseteq A_2 \supseteq... \in
  \mathcal R$ satisfy $\bigcap_{n=1}^\infty A_n = \emptyset$ and
  $\varepsilon>0$. Let $\delta_1, \delta_2,... >0$ with
  $\sum_{n=1}^\infty \delta_n < \varepsilon$. For each $n$, let
  $\mathcal C \ni C_n \subseteq A_n \in \mathcal R$ with $\mu(A_n)
  \leq \mu(C_n) + \delta_n$. We have that $\bigcap_{n=1}^\infty C_n
  \subseteq \bigcap_{n=1}^\infty A_n = \emptyset$, so there is $N \in
  \mathbb N$ with $\bigcap_{n=1}^N C_n = \emptyset$ since $\mathcal C$
  is a compact system. So, for any $m>N$, we have that
  \begin{align*}
     \mu(A_m) & = \mu\Big( \Big(\bigcap_{n=1}^m A_n\Big) \setminus
     \Big(\bigcap_{n=1}^m C_n\Big)\Big) \leq \sum_{n=1}^m \mu(A_n
     \setminus C_n) \\ & \leq \sum_{n=1}^m \delta_n < \varepsilon.
  \end{align*}
  This concludes the proof.
\end{proof}

%% def closedCompactCylinders :
%%   Set (Set ((i : ι) → α i)) :=
%%   ⋃ (s) (S) (_ : IsClosed S) (_ : IsCompact S), {cylinder s S}

%%     theorem isCompactSystem_cylinders :
%% IsCompactSystem (fun t ↦ t ∈ closedCompactCylinders α)

%% lemma AddContent.sigma_additive_of_regular [Nonempty α] (hR : SetRing R) (m : AddContent R)
%%     (hm_ne_top : ∀ {s} (_ : s ∈ R), m s ≠ ∞)
%%     (hC : IsCompactSystem C) (hCR : C ⊆ R)
%%     (h_reg : ∀ A (_ : A ∈ R) (ε : ℝ≥0∞) (_ : 0 < ε), ∃ K ∈ C, K ⊆ A ∧ m (A \ K) ≤ ε)
%%     ⦃f : ℕ → Set α⦄ (hf : ∀ i, f i ∈ R) (hUf : (⋃ i, f i) ∈ R) (h_disj : Pairwise (Disjoint on f)) :
%%     m (⋃ i, f i) = ∑' i, m (f i)

%In our formalization, we are less general and use a direct argument
%for a \leanlinecolor{kolContent}. More precisely, we show that a
%\leanlinecolor{kolContent}, which is based on a projective family
%which is inner regular with respect to compact and closed sets is
%$\sigma$-additive.

In order to apply this result and show the extension theorem, we need
to show that
%$\{\pi_J^{-1} C: C \in \prod_{j\in J} \alpha_j \text{ compact}\}$ as
%  well as
$\{\pi_J^{-1} C: C \in \prod_{j\in J} \alpha_j \text{ compact and
  closed}\}$ is a compact systems. Note that compact sets are closed
in Hausdorff spaces, but we do not have this property since we are
working with pseudo-metric spaces. Since Lemma~\ref{l:stetigcompact}
gives the $\sigma$-additivity of a \leanlinecolor{kolContent}, which
is defined through the projective family \leanline{P}, we have:

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem kolContent_sigma_additive_of_innerRegular
    (hP : IsProjectiveMeasureFamily P)
    (hP_inner : ∀ J,
      (P J).InnerRegular (fun s => IsCompact s ∧ IsClosed s)
      MeasurableSet)
    ⦃f : ℕ → Set (∀ i, α i)⦄ (hf : ∀ i, f i ∈ cylinders α)
    (hf_Union : (⋃ i, f i) ∈ cylinders α)
    (h_disj : Pairwise (Disjoint on f)) :
    kolContent hP (⋃ i, f i) = ∑' i, kolContent hP (f i)
\end{minted}

Note that the assumption \leanline{hP_inner} from above translates
directly to inner regularity of the \leanlinecolor{kolContent}, which
is defined through the projective family \leanline{P}. Moreover, since
the Carathéodory extension theorem requires $\sigma$-subadditivity
(rather than $\sigma$-additivity), we can use
\leanlinecolor{sigma_subadditive_of_sigma_additive} (see
  Lemma~\ref{P:stetigmass}, 1.$\Rightarrow$2.) in order to show that
the assumptions of the last result also imply $\sigma$-subadditivity;
this gives
\leanlinecolor{kolContent_sigma_subadditive_of_innerRegular}.

%  theorem kolContent_sigma_subadditive_of_innerRegular
%    (hP : IsProjectiveMeasureFamily P)
%    (hP_inner : ∀ J,
%      (P J).InnerRegular (fun s => IsCompact s ∧ IsClosed s)
%      MeasurableSet)
%    ⦃f : ℕ → Set (∀ i, α i)⦄
%    (hf : ∀ i, f i ∈ cylinders α)
%    (hf_Union : (⋃ i, f i) ∈ cylinders α) :
%    kolContent hP (⋃ i, f i) ≤ ∑' i, kolContent hP (f i)



What remains to be done is to show conditions under which the
projective family is inner regular with respect to compact (and
closed) sets. For this, we need some assumption on the underlying
spaces.

The next result is already implemented in \leanline{mathlib}: Use
\leanline{Measure.InnerRegular.of_pseudoEMetricSpace} in order to show
that every open set is inner regular with respect to closed sets, and
\leanline{Measure.InnerRegular.measurableSet_of_open} to show that
every measurable set is inner regular with respect to closed sets.
The claimed outer regularity is part of
\leanline{MeasureTheory.Measure.InnerRegular.weaklyRegular_of_finite}.

\begin{lemma}\label{l:pseude1}
  Let $r$ be an extended pseudo-metric on $\alpha$, and the topology
  on $\alpha$ be given by $r$. If $\mu$ is a finite measure on the
  Borel $\sigma$-algebra $\mathcal B$ on $\alpha$, it is inner regular
  with respect to closed sets. In fact, we have also outer regularity
  with respect to open sets, i.e.\ for all $A\in \mathcal B$,
  $$ \mu(A) = \inf \{ \mu(O) : A \subseteq O \text{ open}\}.$$
\end{lemma}

\begin{proof}
  It suffices to prove that
  $$ \mathcal A := \Big\{A \in \mathcal B : \mu(B) = \sup_{F\subseteq
    B \text{ closed}} \mu(F) = \sup_{B\subseteq O \text{ open}}
  \mu(O)\Big\} $$ is a $\sigma$-algebra containing all closed
  sets. So, we proceed in two steps.  \\ {\em Step 1: $\mathcal A$ is
    a $\sigma$-algebra:} Since $\mu$ is finite, we have that $\mu(A^c)
  = \mu(\alpha) - \mu(A)$ for all $A$. Using this, we already have
  that $\mathcal A$ is closed under complements. So, we are left with
  showing that $\mathcal A$ is closed under countable unions. For
  this, let $A_1, A_2,... \in \mathcal A$ and $A :=
  \bigcup_{n=1}^\infty A_n$. Fix $\varepsilon > 0$ and a sequence
  $\delta_1, \delta_2,... > 0$ with $\sum_{n=1}^\infty \delta_n <
  \varepsilon$. For each $n$, let $F_n \subseteq A_n \subseteq O_n$
  with $F_n$ closed, $O_n$ open and $\mu(O_n \setminus F_n) \leq
  \delta_n$. Then, $O := \bigcup_{n=1}^\infty O_n$ is open and
  $$ 0 \leq \mu(O) - \mu(A) \leq \sum_{n=1}^\infty \mu(O_n \setminus
  A) \leq \sum_{n=1}^\infty \mu(O_n \setminus A_n) < \varepsilon.$$
  This shows outer regularity of $\mu$ with respect to open sets at
  $A$. It remains to show inner regularity with respect to closed
  sets. For this, note that $\bigcup_{n=1}^N F_n$ is closed for all
  $N$ and recall from Proposition~\ref{P:stetigmass} that $\mu$ is
  continuous from below. Therefore, setting $F := \bigcup_{n=1}^\infty
  F_n$,
  \begin{align*}
    0 & \leq \mu(A) - \lim_{N\to\infty} \mu\Big(\bigcup_{n=1}^N
    F_n\Big) = \mu(A \setminus F) \leq \sum_{n=1}^\infty \mu(A_n
    \setminus F) \\ & \leq \sum_{n=1}^\infty \mu(A_n \setminus F_n) <
    \varepsilon.
  \end{align*}
  This shows inner regularity of $\mu$ with respect to closed sets at
  $A$.


  \noindent
  {\em Step 2: $\mathcal A$ contains all closed sets:} Let
  $\varepsilon_ n\downarrow 0$ and, for $\varepsilon>0$ and some $A
  \subseteq \alpha$, $A^\varepsilon := \{x : \exists y \in A,
  r(x,y)<\varepsilon\}$. Then, for $A$ closed, we have that $A =
  \bigcap_{n=1}^\infty A^{\varepsilon_n}$ and $A^{\varepsilon_n}$ is
  open for all $n$. Clearly, $\mu(A) = \sup\{\mu(F): F\text{ closed},
  F \subseteq A\}$, since $A$ is closed. By continuity of $\mu$, we
  find that $\mu(A^{\varepsilon_n}) \xrightarrow{n\to\infty} \mu(A)$,
  therefore $\mu(A) = \inf\{\mu(O): F\text{ open}, A \subseteq O\}$,
  and we have shown that $A \in \mathcal A$.
\end{proof}

%xxx From Remy: For \leanline{inner_regular_etc} we already do it in
%three parts: our result shows \leanline{P.inner_regular (λ s,
%is_compact s ∧ is_closed s) is_closed}, then we go from closed to
%open sets thanks to
%\leanline{docs3#measure_theory.measure.inner_regular.of_pseudo_emetric_space},
%and finally to measurable sets with
%\leanline{docs3#measure_theory.measure.inner_regular.measurable_set_of_open}. That
%last step uses the borel space assumption in the typeclass inference
%process to get its \leanline{outer_regular} argument.

In the next lemma, we will need that a closed subset of a compact set
is compact. (See \leanline{isCompact_of_isClosed_subset}.) We describe
the formalization of the next lemma only in conjunction with
Lemma~\ref{L:relcoPol}. We omit the proof, since the
  only interesting part is an application of inner regularity from
  Lemma~\ref{l:pseude1}.

\begin{lemma}\label{l:tight}
  Let $r$ be an extended pseudo-metric on $\alpha$, and the topology
  on $\alpha$ be given by $r$. If $\mu$ is a finite measure on the
  Borel $\sigma$-algebra $\mathcal B$ on $\alpha$, the following are
  equivalent:
  \begin{enumerate}
    \item For all $\varepsilon>0$, there is some closed and compact
      $K$ with $\mu(K^c) < \varepsilon$.
    \item For all $\varepsilon>0$ and $A \in \mathcal B$, there is
      some closed and compact $K\subseteq A$ with $\mu(A \setminus K)
      < \varepsilon$.
  \end{enumerate}
\end{lemma}

%% \todo{too much detail? omit the proof?}

%% \begin{proof}
%%   2. $\Rightarrow$ 1.: This is clear since $\alpha \in \mathcal B$.
%%   1. $\Rightarrow$ 2.: Fix $\varepsilon>0$ and $A \in \mathcal B$. Let
%%   $K$ be closed and compact with $\mu(K^c) < \varepsilon/2$. By
%%   Lemma~\ref{l:pseude1}, there is some closed $F \subseteq A$
%%   with $\mu(A) < \mu(F) + \varepsilon/2$. Now, we have that $F \cap K
%%   \subseteq A$ is closed and compact, and with $A \setminus (F\cap K)
%%   = (A \setminus F) \cup (A \setminus K)$,
%%   $$\mu(A \setminus (F\cap K)) \leq \mu(A \setminus F) + \mu(A
%%   \setminus K) < \varepsilon/2 + \mu(K^c) < \varepsilon. $$
%% \end{proof}

We apply this result by using that 1.\ is satisfied for complete and
separable extended pseudo-metric spaces. Here, for the generalization
to extended pseudo-metric spaces, we use that any subset of such a
space is compact iff it is complete and totally
bounded\footnote{\label{note:tot}A subset of a pseudo-metric space is
  totally bounded iff, for all $\varepsilon>0$, it can be covered by
  finitely many balls of radius $\epsilon$.} (see
\leanline{isCompact_iff_totallyBounded_isComplete} in {\tt
  mathlib}). Since closed subsets of a complete space are complete,
the closure of a totally bounded set is (still totally bounded, hence)
compact. (This fact is used in the proof below.)

\begin{lemma}\label{L:relcoPol}
  Let $\alpha$ be a complete and separable, extended pseudo-metric
  space, and $\mu$ a finite measure on its Borel $\sigma$-algebra
  $\mathcal B$. Then, for any $\varepsilon>0$, there is some
  $K\subseteq \alpha$ with compact closure and\footnote{We write $\bar
    K$ for the closure of $K$.}  $\mu((\bar K)^c)<\varepsilon$.
\end{lemma}

\begin{proof}
 Since $\alpha$ is separable, there is a subset $\{x_1, x_2,...\}
 \subseteq_c \alpha$ with closure $\alpha$. By separability, for each
 $n\in \mathbb N$, $\alpha = \bigcup_{k=1}^\infty
 B_{\varepsilon_n}(x_k)$. Since $\mu$ is continuous from above in
 $\emptyset$ (see Lemma~\ref{P:stetigmass})
  \[
  0 = \mu\Big(\Big(\bigcup_{k=1}^\infty B_{\varepsilon_n}(x_k)\Big)^c
  \Big) = \lim_{N\to\infty} \mu\Big( \Big(\bigcup_{k=1}^N
  B_{\varepsilon_n}(x_k)\Big)^c\Big).
  \]
  Let $\delta_n\downarrow 0$ be summable with $\sum_{n=1}^\infty
  \delta_n = 1$ (e.g.\ $\delta_n = 2^{-n}$). Then, there is some
  $N_n\in\mathbb N$ with $\mu\Big( E\setminus \bigcup_{k=1}^{N_n}
  B_{\varepsilon_n}(x_k)\Big) < \varepsilon \delta_n$. Now take
  \[
    A := \bigcap_{n=1}^\infty \bigcup_{k=1}^{N_n}
    B_{\varepsilon_n}(x_k),
  \]
  which by construction is totally bounded (for $r>0$ take $n$ such
  that $\varepsilon_n < r$, such that $B_r(x_1),...,B_r(x_{N_n})$
  cover $A$), and therefore has a compact closure as noted
  in the lines directly preceding the lemma. Finally, by $\sigma$-sub-additivity of $\mu$,
  \begin{align*}
     \mu((\overline A)^c) & \leq \mu(A^c) = \mu\Big(
     \bigcup_{n=1}^\infty \Big(\Big(\bigcup_{k=1}^{N_n}
     B_{\varepsilon_n}(x_k)\Big)^c\Big)\Big) \\ & \leq
     \sum_{n=1}^\infty \mu\Big( \Big(\bigcup_{k=1}^{N_n}
     B_{\varepsilon_n}(x_k)\Big)^c\Big)< \varepsilon
     \: .
  \end{align*}
\end{proof}

Combining the last two results, we obtain the desired statement that a measure on a second countable,
complete extended pseudo-metric space is inner regular with respect to
closed compact sets.

\begin{minted}[highlightlines={1-2}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
theorem innerRegular_isCompact_isClosed_
    measurableSet_of_complete_countable
    [PseudoEMetricSpace α] [CompleteSpace α]
    [SecondCountableTopology α]
    [BorelSpace α] (P : Measure α) [IsFiniteMeasure P] :
    P.InnerRegular (fun s => IsCompact s ∧ IsClosed s)
      MeasurableSet
\end{minted}

%\begin{lemma}\label{l:totalBoundcompact}
%  Let $E$ be a uniform topologocal space\footnote{This is more general
%    than a metric space, i.e.\ every metric space is uniform.} Then,
%  $A\subseteq E$ is compact iff it is totally bounded\footnote{In a
%    metric space, this means that forall $\varepsilon>0$ you find a
%    finite number of balls covering the set} and
%  complete\footnote{i.e.,\ Cauchy filters converge.}.
%\end{lemma}

%\noindent
%The usual way to apply this result is in a Polish space. Here, $A$ is
%relatively compact iff it is totally bounded.

%\noindent
%Although, regularity of measures is covered in {\tt mathlib}, the next
%statement is not yet part of the library. Similar constructions will
%be important for Prohorov's theorem in the theory of weak convergence.
%In Lean, we can use \verb+ measure_theory.measure.inner_regular+ for
%the statement of this result. In the proof of the lemma, we will be
%using the last fact

\subsection{Proof of Kolmogorov's extension theorem}
We now describe the proof of Kolmogorov's extension theorem as well as
its formalization: For the proof of Theorem~\ref{T1}, we
\begin{enumerate}
  \item apply Theorem~\ref{T:masseind} for the ring (hence semi-ring)
    $\mathcal A$ and the set-function $P$ as given in
    Theorem~\ref{T1};
  \item show $\sigma$-additivity (as assumed in
    Theorem~\ref{T:masseind}) of $P$ by using
    Lemma~\ref{l:stetigcompact}. For the latter, we need to show that
    $P$ is inner regular with respect to a compact system. Here, note
    that $\{\pi_J^{-1}C : C \in \prod_{j\in J} \alpha_j \text{ compact
      and closed}\}$ is a compact system and $P(\pi_J^{-1}C) =
    P_J(C)$, so we need to show that $P_J$ is inner regular with
    respect to compact closed sets, $J\subseteq_f \iota$;
  \item use Lemma~\ref{L:relcoPol} in combination with
    Lemma~\ref{l:tight} (1.$\Rightarrow$2.) and the properties of
    completeness, separability of the underlying extended
    pseudo-metric spaces in order to see that every $P_J$ has the
    desired property of being inner regular wrt compact and closed
    sets. This concludes the proof of Theorem~\ref{T1}.
\end{enumerate}
The formalization of this proof resembles these arguments. We leave
out all instances in the reformulation of the result and its proof
(see below Theorem~\ref{T1} for a full formulation):

\begin{minted}[highlightlines={1}, mathescape, numbersep=5pt, framesep=5mm, bgcolor=mygray]{Lean}
def projectiveLimitWithWeakestHypotheses
    (P : ∀ J : Finset ι, Measure (∀ j : J, α j))
    (hP : IsProjectiveMeasureFamily P) :
    Measure (∀ i, α i) :=
  Measure.ofAddContent setSemiringCylinders
    generateFrom_cylinders (kolContent hP)
    (kolContent_sigma_subadditive_of_innerRegular hP
      fun J => innerRegular_isCompact_isClosed_
      measurableSet_of_complete_countable (P J))
\end{minted}
\sloppy Let us look closer at the formalized proof:
\leanlinecolor{kolContent_sigma_subadditive_of_innerRegular} has the
same hypotheses as
\leanlinecolor{kolContent_sigma_additive_of_innerRegular},
except \leanline{h_disj}. So, the lemma in the last brackets shows
$\sigma$-sub-additivity of the content $P$ from
Theorem~\ref{T1}. Then, \leanlinecolor{generateFrom_cylinders} gives
the \leanline{MeasurableSpace} on which we define the
\leanlinecolor{addContent}.
