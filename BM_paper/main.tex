\documentclass[lean]{Draft}

\input{preamble}

\addbibresource{biblio.bib}
\usepackage{tikz}
\usetikzlibrary{arrows, arrows.meta}
\definecolor{ghpurple}{rgb}{0.4, 0.22, 0.73}

% \hypersetup{
%   colorlinks = true,
%   citecolor = teal,
%   linkcolor = teal,
%   urlcolor = ghpurple
% }

\newcommand{\changeurlcolor}[1]{\hypersetup{urlcolor=#1}}
\newcommand{\lsthref}[2]{\changeurlcolor{ghpurple}{\ttfamily\href{#1}{#2}}}
\newcommand{\leanok}{\qed}
\newcommand{\uses}[1]{Uses #1}
\newcommand{\mathlibok}{}
\renewcommand{\lean}[1]{\lstinline| #1|}

\makeatletter
\newcommand\leanlink{\begingroup\catcode`\#=12\relax\@leanlink}
\newcommand\@leanlink[2]{\endgroup
\href{#1}
{\texttt{\detokenize{#2}}}}

\newcommand{\docs}[1]{%
\href{https://leanprover-community.github.io/mathlib4_docs/find/?pattern=#1\#doc}
{\texttt{\detokenize{#1}}}}

\lstset{escapeinside={(*}{*)}, language=lean}

\title[Formalization of Brownian motion in Lean]{Formalization of Brownian motion in Lean}
\author[R. Degenne, M. Himmel, D. Ledvinka, E. Marion, P. Pfaffelhuber]{
  Rémy Degenne, Markus Himmel, David Ledvinka, Etienne Marion, Peter Pfaffelhuber}


\authorinfo[R. Degenne]{Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189-CRIStAL, F-59000 Lille, France}{remy.degenne@inria.fr}
\authorinfo[M. Himmel]{University of XYZ, Country}{markus.himmel@example.com}
\authorinfo[D. Ledvinka]{University of XYZ, Country}{david.ledvinka@example.com}
\authorinfo[E. Marion]{University of XYZ, Country}{etienne.marion@example.com}
\authorinfo[P. Pfaffelhuber]{University of Freiburg, Germany}{p.p@stochastik.uni-freiburg.de}

% please fill in
\msc{TODO}
\keywords{Formalization, Mathlib, Lean, Brownian motion}

%update
\VOLUME{TODO}
\YEAR{TODO}
\NUMBER{TODO}
\firstpage{1}
\DOI{TODO}
\receiveddate{TODO}
\finaldate{TODO}
\accepteddate{TODO}


\begin{abstract}
Brownian motion is a building block in modern probability theory. In this paper, we describe a formalization of Brownian motion using the Lean theorem prover. We build on the existing measure-theoretic foundations in Lean's mathematical library, Mathlib, and we develop several key components needed for the construction of Brownian motion, including the Carathéodory and Kolmogorov extension theorems, Gaussian measures in Banach spaces, and the Kolmogorov-Chentsov theorem for path continuity.
\end{abstract}

\begin{document}

\href{https://github.com/RemyDegenne/brownian-motion}{github}

% Some useful commands:
% \mathlib{}
% \leanlink{url}{this is a link to Lean code}

% Inline code: \lstinline|sorry|

% Multi-line code:
% \begin{lstlisting}
% /-- A process `X : T → Ω → E` has independent increments if for any `n ≥ 2` and `t₁ ≤ ... ≤ tₙ`,
% the random variables `X t₂ - X t₁, X t₃ - X t₂, ...` are independent. -/
% def HasIndepIncrements {Ω T E : Type*} {mΩ : MeasurableSpace Ω} [Sub E]
%     [Preorder T] [MeasurableSpace E] (X : T → Ω → E) (P : Measure Ω) : Prop :=
%   ∀ n, ∀ t : Fin (n + 2) → T, Monotone t →
%     iIndepFun (fun i : Fin (n + 1) ↦ X (t i.succ) - X (t i.castSucc)) P
% \end{lstlisting}

\section{Introduction}

\subsection{Mathematical background}
\sloppy Brownian motion is arguably one of the most important stochastic processes (e.g.\ \cite{karatzas1991brownian, morters2010brownian}), and is used as a modeling tool across all sciences (physics: e.g.\ \cite{einstein1906theorie, bian2016111}; biology: e.g.\ \cite{erban2014molecular}; finance: e.g.\ \cite{davis2006louis}). Mathematically, Brownian Motion led to Wiener measure \cite{wiener1923differential}, which is the first instance of a probability measure on a function space, but also to developments such as Stochastic (Partial) Differential equations (see e.g.\ \cite{hairer2009introduction}).

Let us briefly describe Brownian motion $X = (X_t)_{t\geq 0}$. There are several interesting features (considering the one-dimensional version and if $X_0=0$):
\begin{itemize}
\item It has a normal distirbution at all times; more precisely, for any $t_1,...,t_n > 0$, we have that $(X_{t_1},...,X_{t_n})$ has a multivariate normal distribution, with $\mathbf E[X_{t_i}] = 0$ and $\mathbf{COV}(X_{t_i}, X_{t_j}) = t_i \wedge t_j$ (in other words, $X$ is a Gaussian process);
\item Its states after time $t$ are independent of states before $t$ given $X_t$, or $\mathbb P(X_{t+s} \in . | (X_r)_{r\leq t}) = \mathbb P(X_{t+s} \in . | X_t)$ for $s,t \ge 0$, i.e.\ Brownian Motion is a Markov process;
\item It has independent increments, which only depend on the evolved time, i.e.\ $X_s$ and $X_t - X_s$ are independent, and $X_t - X_s$ is a function of $t-s$, i.e.\ it is a Lévy process;
\item It describes a fair game (usually denoted a martingale), i.e.\ $\mathbb E[X_{t+s} | (X_r)_{r\leq t}] = X_t$ for $s,t \geq 0$; interestingly, it is the only stochastic process with continuous paths such that $(X_t)_{t\geq 0}$ and $(X_t^2 - t)_{t\geq 0}$ are martingales;
\item It has continuous paths (almost surely); more precisely, it has Hölder-continuous paths for any coefficient $\beta < \tfrac 12$; as a consequence, its paths are nowhere differentiable, almost surely;
\end{itemize}
The goal of the present paper is to describe a formalization project of Brownian Motion using Lean \cite{lean}, building on its mathematical library. Since Mathlib \cite{mathlib} has a decent amount of measure theory already included, but is still lacking some fundamentals, we describe our way to a full formalization using the following steps:
\begin{itemize}
\item {\em The Carathéodory and Kolmogorov Extension Theorems:} Constructing a probability measure on an uncountable infinite product (i.e.\ the distribution of a stochastic process) is not straight-forward, since the corresponding product of $\sigma$-algebras is too large. Rather, one uses the $\sigma$-algebra defined by all finite (or countably infinite) projections, and constructs a probability measure by extension from all finite dimensional possibilities, which is the content of the Kolmogorov Extension Theorem. This result is in fact an application of a more general result, the Carathèodory Extension Theorem. In this step, we need that the family of finite dimensional distirbutions has a consistency property (i.e.\ it forms a projective family).
\item {\em Gaussian Measures and characteristic functions:} Defining a one-dimensional normal distribution is straight-forward using its density with respect to Lebesgue measure, and concrete calulations are often possible using the density. In the multi-dimensional case, which we have to work with extensively, it is often much more convenient to use characteristic functions, which are known to characterize probability measures uniquely. In particular, they can be used to show that linear maps (e.g.\ projections) of Gaussian measures are Gaussian. This approach is fundamental to show that finite dimensional distirbutions of Brownian Motion indeed form a projective family.
\item {\em The Kolmogorov-Chentsov Theorem:} We are aiming for a stochastic process with continuous paths. The classical Kolmogorov Chentsov theorem gives a criterion in terms of some moment bounds if the set of times is a subset of $\mathbb R^d$; see e.g.\ \cite{kallenberg2021}. Here, we use a modern version for existence of a modification of a stochastic process with continuous paths, based on a more general set of times \cite{kratschmer2023kolmogorov}.
\item {\em Construction of Brownian motion and Wiener measure on $\R_+$:} Putting all of the above together gives a continuous Gaussian stochastic process with the correct distribution, i.e.\ Brownian Motion. From this, we can also define a probability measure on (the Polish space) of continuous functions $\mathbb R_+ \to \mathbb R$. This is usually called the Wiener measure.
\end{itemize}
It is important to realize that probability theory comes with a duality between random variables (or stochastic processes) and their distributions (or laws), which are probability measures. In the case of stochastic processes, the latter are defined on the (often uncountable infinite) product on the state space. While some properties of a stochastic process are only dependent on their distribution (e.g.\ being a Gaussian process), other properties depend on more refined properties (e.g.\ having continuous paths). We account for this duality in our code by introducing in the assumptions that a certain law is required.

\subsection{Related work}
In the literature, there are some formalizations of stochastic processes. Within Isabelle/HOL, the Kolmogorov extension theorem has been previously formalized \cite{Immler2012}. This formalization only works on Polish spaces (rather than on spaces where every finite measure is inner regular with respect to compact sets, see below), and only in the case where the state spaces for all times are identical. As for the Kolmogorov-Chentson-Theorem (showing continuity of paths), there is an Isabelle/HOL formalization as well \cite{Kolmogorov_Chentsov-AFP}. It uses the index set  $\R_+$ (rather than a more general type) with the usual dyadics proof, as e.g. outlined in \cite{kallenberg2021}. Last,
Brownian motion in implemented in Isabelle/HOL at \cite{laursen2024brownian} (the code is on \href{https://github.com/cplaursen/Brownian_Motion}{github})\todorm{the formalization does not look complete}. As the authors say, dependent type theory would have facilitated their work in places.

For the Lean theorem prover, \cite{ying2023formalization} formalized martingales (see e.g.\ \cite{kallenberg2021}) and was the first implementation of stochastic processes. In our work, however, we do not touch martingales, and rather build on implementations of measure theory, as implemented in \cite{mathlib}. We benefitted from recent efforts to write code and a description of the proofs using the blueprint tool \cite{Monticone_LeanProject_2025}.

\section{The formalization}
Let us start with our notation. Any stochastic process has an index set $\iota$ (usually denoted {\em time}, usually uncountably infinite), and a state space. Since we use dependent type theory, the state space may depend on the time, i.e.\ the state space at time $t$ is $\alpha t$. Probability measures are denoted $P_.$.

All references to results in \mathlib are accurate for commit {\tt xxx}, August 22, 2025.

\subsection{The Carathéodory and Kolmogorov Extension Theorems}
The usual approach to construct (the distribution of) a stochastic process works as follows: describe properties of the distribution of the stochastic process $P_J$ at some arbitrary but finite number of times $J = \{t_1,...,t_n\} \subseteq \iota$.
The resulting family of probability measures $(P_J)_{J \subseteq \iota \text{ finite}}$ has to be {\em projective} in the sense that the projection of $P_J$ to $H\subseteq J$ has to be equal to $P_H$. In other words, when describing the distribution of the stochastic process at all times in $J$, and then forgetting all properties for times in $J\setminus H$, results in the description of properties at times in $H$. One may then ask if this already gives a complete description of the process for all times.

It is the achievement of Kolmogorov that these finite-dimensional distributions in fact provide a unique description of the distribution of a stochastic process, even if $\iota$ is uncountable, as long as the underlying family of state spaces $(\alpha_t)_{t\in\iota}$ is nice enough (Polish, i.e.\ a separable topological space which can be metrized by a complete metric, for example) \cite{kolmogoroff1933grundbegriffe}.
The resulting measure is defined on the product-$\sigma$-field $\mathcal F :=\bigotimes_{t\in\iota} \mathcal B(\alpha_t)$ (where $\mathcal B(\alpha_t)$ is the Borel $\sigma$-algebra on $\alpha_t$). Here, $\mathcal F$ is generated by finite projections and hence any element of $\mathcal F$ may only depend on at most countably many $t\in \iota$, making this a rather coarse $\sigma$-algebra. (In particular, note that this is not the Borel $\sigma$-algebra of the product topology for infinite $\iota$.)

The Kolmogorov extension theorem is on the interface between measure theory and probability theory. Here, we rely on a decent amount of formalized mathematics in the measure-theory part of {\tt mathlib} (outer measures, above all), while not requiring any specific previous formalization of probability theory. (In fact, most of our results are formulated in terms of finite rather than probability measures.)

We are going to formulate the main result in a modern fashion, as e.g.\ found in Theorem 2.2 of \cite{rao1971projective}, Theorem 7.7.1 of Volume~2 of \cite{bogachev2007measure}, Theorem 15.26 of \cite{guide2006infinite}, or \cite{border1998expository}. Note that these formulations split general assumptions on the underlying space(s) (e.g.\ a metric property) from the property which is needed in the proof (inner regularity with respect to compact sets). Other -- highly readable -- references such as \cite{Billingsley1995} state the extension theorem only in special cases such as $\alpha_t = \mathbb R$ for all $t$.


\subsection{Gaussian Measures and characteristic functions}
\label{ss:char}
Our goal in this subsection is to define the finite-dimensional distributions of Brownian Motion. For times $t := (t_1, ..., t_n)$, this is given by the multi-dimensional Gaussian distribution $N(0, C_t)$, where $0$ is the vector of expectations, and $C_t$ is the covariance matrix, given by $C_{ij} = t_i \wedge t_j$. In order to do so, we rely on (i) the implementation of the one-dimensional normal distribution (xxx ref to mathlib) and characteristic functions of probability (or finite) measures.

For any probability measure $P$ on $\mathbb R^n$, its characteristic function is given by $\psi: t \mapsto \int e^{it^\top x} P(dx)$, where the integral takes values in $\mathbb C$. We use the fact that $\psi$ characterizes $P$ uniquely (xxx ref to mathlib). For the standard normal distribution $N(0,1)$ this is $\psi_{N(0,1)}(t) = \exp(-t^2/2)$. Moreover, by independence, we can as well define the $n$-fold product measure $N(0, I_n)$, where $I_n$ is the unit matrix with characteristic function $\psi_{N(0,I_n)}(t) = \exp\big(-\tfrac 12 t^\top I_n t\big)$. In addition, we call a probability measure $P$ on $\R^n$ Gaussian if there is some non-negative definite matrix $C$ with $\psi_P(t) = \exp\big( - \tfrac 12 t^\top C t\big)$. For any such $C$, such a measure exists, since there is $A$ with $C = A^\top A$ (xxx ref to mathlib) and there is the image of $N(0,I_n)$ under the map $f : x\mapsto Ax$. It has the caracteristic function
\begin{align} \label{eq:gausslin}
\psi_{f_\ast N(0,I_n)}(t) = \int e^{it^\top x} f_\ast N(0,I_n) dx = \int e^{it^\top A x} N(0,I_n) dx = \exp\big( - \tfrac 12 t^\top C t\big).
\end{align}
Using the same transformation, we can show that Gaussian measures are closed under linear maps.

So, we can define the finite dimensional distributions of Brownian motion given that we show that $C \in \R^n$ with entries $C_{ij} = t_i \wedge t_j$ is non-negative definite. For this, we rely on Gram matrices, which are based on inner product spaces. In such a space $E$ (with scalar product $\langle .,. \rangle$), and $v_i,...,v_n \in E$, define $C_{ij} := \langle v_i, v_j\rangle$. Then, for $t :=(t_1,...,t_n) \in \R^n$,
$$ t^\top C t = \sum_{i,j} t_i \langle v_i, v_j\rangle t_j = \Big\langle \sum_i t_i v_i, \sum_j t_j v_j\Big\rangle \geq 0.$$
Let $v_i = 1_{[0,t_i]}$ in the space of $L^2$ integrable functions with respect to Lebesgue integral. Then,
$$ \langle v_i, v_j \rangle = \int 1_{[0,t_i]}(x) 1_{[0,t_j]}(x) dx = \int 1_{[0,t_i \wedge t_j]}(x) dx = t_i \wedge t_j.$$
So, $C$ from above is a Gram matrix, which is non-negative definite by general theory, and we have constructed the finite dimensional distributions for Brownian motion.

\cite{hairer2009introduction}

\subsection{The Kolmogorov-Chentsov Theorem}
Let us describe briefly the Kolmogorov-Chentsov Theorem in a simple case here, before we dive deeper in the next sections. The result states that for a stochastic process $X$ (with $\iota = [0,1])$, assume we find $\alpha, \beta, C > 0$ satisfying
\begin{align}
\label{eq:cs}
  \mathbf E[r(X_s, X_t)^\alpha] \leq C|t-s|^{\beta + 1}, \qquad 0\leq s,t\leq 1.
\end{align}
Then there exists $Y = (Y_t)_{t\in [0,1]}$ with $\mathbf P(X_t = Y_t) = 1$ for all $t\in [0,1]$ and $Y$ has almost surely Hölder continuous paths with coefficient $\gamma$ for any $\gamma < \tfrac \beta \alpha$.

In order to see this, set $D_n := \{k/2^n: k=0,...,2^n\}$ and $D := \bigcup_{n\in\mathbb N} D_n$. Start by showing summability of $\mathbf P\Big( \sup_{s,t\in D_n, |t-s| = 2^{-n}} r(X_s, X_t) \geq 2^{-\gamma n} \Big)$ using \eqref{eq:cs}. By the Borel-Cantelli Lemma, this shows that $\sup_{s,t\in D_n, |t-s| = 2^{-n}} r(X_s, X_t) \leq 2^{-\gamma n}$ holds for $n$ large enough. From this, we see that $X$ is locally Hölder-$\gamma$ continuous on $D$. From here, define some Hölder continuous $Y$ coinciding with $X$ on $D$. Finally, fix $t \in [0,1]$ and $t_1, t_2,...\in D$ with $t_n \xrightarrow{n\to\infty} t$. Using \eqref{eq:cs}, we see that $X_{t_n} \xrightarrow{n\to\infty} X_t$ in probability, as well as $Y_{t_n} \xrightarrow{n\to\infty} Y_t$ almost surely due to continuity of $Y$. Therefore, $X_t = Y_t$ almost surely.

We will use a more general version of this statement, replacing $\iota = [0,1]$ by a metric space with a property restricting the number of balls needed to cover $\iota$. This is based on recent work of \cite{talagrand2022upper} and \cite{kratschmer2023kolmogorov}.

\subsection{Construction of Brownian motion and Wiener measure on $\R_+$}
In order to finally construct Brownian Motion, we need to put everything together. First, the projectivity property of the finite-dimensional distributions as defined in Section~\ref{ss:char} follows from the fact that Gaussian measures are closed under linear maps, and -- as in \eqref{eq:gausslin} -- the characteristic function of the image of $N(0,C)$ under the linear map $\Pi : x \mapsto \pi x$ is $\Psi_{\Pi_\ast N(0,C)}(t) = \exp\Big( -\tfrac 12 t^\top \pi^\top C \pi t \Big)$. So, for $t = (t_1,...,t_n)$ and $C(t) \in \mathbb R^{n\times n}$ with $C(t)_{ij} = t_i \wedge t_j$ and the projection $\Pi: \mathbb R^n \to \mathbb R^m$ with $m < n$ and $\Pi(t) = (s_1,...,s_m)$, this shows that $\Pi_\ast N(0,C(t)) = N(0,C(s))$, which is the desired projectivity. Therefore, we have constructed a probability measure on $\mathbb R_+^{\mathbb R}$, the law of Brownian motion.\\
Finally, the assumption in the Kolmogorov-Chentsov Theorem can e.g.\ be verified by using that
\[ \mathbf E[|X_t - X_s|^4] = \mathbf E[X_{t-s}^4] = (t-s)^2 \mathbf E[X_{1}^4] < \infty.\]
So, we have constructed a process with continuous paths and the correct finite dimensional distributions, which we call Brownian Motion. Since this also gives a distribution on $\mathcal C(\mathbb R_+, \mathbb R)$, we call this distribution Wiener measure.

\section{The Carathéodory and Kolmogorov Extension Theorems}
\label{S:extension}
We describe our implementation of the Kolmogorov Extension Theorem, and rely on basic notions from topology, such as a metric space, and the Borel $\sigma$-algebra. Recall, however, that a pseudo-metric $r(.,.)$ can have $r(x,y) = 0$ for $x\neq y$.

We begin by defining set systems we will need; see also \docs{MeasureTheory.IsSetSemiring}  and \docs{MeasureTheory.IsSetRing}.

\begin{definition}[Semi-ring, ring]\label{def:semi}
  Let $\alpha$ be some set. We call $\mathcal H \subseteq 2^\alpha$ a
  \emph{semi-ring}, if it is (i) a $\pi$-system (i.e.\ closed under
  $\cap$) and (ii) for all $A, B \in\mathcal H$ there is $\mathcal K
  \subseteq_f \mathcal H$ with\footnote{We write $A\uplus B$ for
    $A\cup B$ if $A\cap B=\emptyset$.}  $B\setminus A = \biguplus_{K
    \in \mathcal K} K$.  \\ We call $\mathcal H \subseteq 2^\alpha$ a
  \emph{ring}, if it is closed under $\cup$ and under set-differences.
\end{definition}

\noindent
Any ring is a semi-ring since $A\cap B = A \setminus (A \setminus B)$, i.e.\ every ring is a $\pi$-system.Let us state two important lemmas on semi-rings; see and
\docs{MeasureTheory.IsSetSemiring.disjointOfDiffUnion} and \docs{MeasureTheory.IsSetSemiring.disjointOfUnion}.

\begin{lemma}\label{l1}
  Let $\mathcal H$ be a semi-ring, $\mathcal I \subseteq_f \mathcal H$,
  $A \in \mathcal H$. Then, there is $\mathcal K \subseteq_f \mathcal
  H$ such that $\mathcal K$ contains pairwise disjoint sets and $A
  \setminus \bigcup_{I \in \mathcal I} I = \biguplus_{K\in \mathcal K}
  K$.
\end{lemma}

\begin{lemma}\label{l2}
  Let $\mathcal H$ be a semi-ring and $A_1,...,A_m \in \mathcal
  H$. Then, there are $\mathcal K_1,...,\mathcal K_m \subseteq_f
  \mathcal H$ disjoint such that $\bigcup_{n=1}^m \mathcal K_n$
  contains disjoint sets and $\bigcup_{m=1}^n A_m = \biguplus_{m=1}^n
  \biguplus_{K \in \mathcal K_n} K$.
\end{lemma}

Given an additive function $m : \mathcal H \to [0,\infty]$ for some semi-ring $\mathcal H$, the goal of Carathéodory's extension theorem is to define a measure $\mu : \sigma(\mathcal H) \to [0,\infty]$ extending $m$. Here, $\sigma(\mathcal H)$ is the $\sigma$-algebra generated by $\mathcal H$. More precisely, the Carathéodory extension gives a measure on an even larger $\sigma$-algebra; see Theorem~\ref{T:cara} below.We will follow this abstract construction, and start by stating some basic concepts; see
\docs{MeasureTheory.AddContent}, \docs{MeasureTheory.Measure}, \docs{MeasureTheory.OuterMeasure}.

\begin{definition}\label{def:content}
  For some set $\alpha$, let $\mathcal H \subseteq 2^\alpha$
  and call any $m : \mathcal H \to [0,\infty]$ a content.
  \begin{enumerate}
  \item $m$ is called additive if for $\mathcal K \subseteq_f \mathcal H$ pairwise disjoint and $\bigcup_{K \in \mathcal K} K \in \mathcal H$, we have $m \Big(\bigcup_{K \in \mathcal K} K \Big) = \sum_{K \in \mathcal K} m(K)$. If the same holds for\footnote {We write $A \subseteq_c B$ if $A$ is a countable subset of $B$.}$\mathcal K \subseteq_c \mathcal H$ pairwise disjoint, we say that $m$ is $\sigma$-additive.
  \item The set-function $m$ is called sub-additive if for $\mathcal K \subseteq_f \mathcal H$ and $\bigcup_{K \in \mathcal K} K \in \mathcal H$, we have $m \Big(\bigcup_{K \in \mathcal K} K \Big) \leq \sum_{K \in \mathcal K} m(K)$. (Note that elements of $\mathcal K$ need not be disjoint.) Here, $\sigma$-sub-additivity is defined in the obvious way using $\mathcal K\subseteq_c \mathcal H$.
  \item If $m(A) \leq m(B)$ for $A\subseteq B$ and $A,B\in\mathcal H$, we say that $m$ is monotone.
  \item If $\mathcal H$ is a $\sigma$-algebra and $m$ is $\sigma$-additive with $m(\emptyset) = 0$, we call
    $m$ a measure.
  \item If $\mathcal H = 2^\alpha$ and $m$ is monotone and $\sigma$-sub-additive with $m(\emptyset)=0$, we call $m$ an outer measure.
  \end{enumerate}
\end{definition}

\subsection{Carathéodory's Extension Theorem}
An additive, $\sigma$-sub-additive content on a semi-ring induces an outer measure by approximating sets from above: (see \docs{inducedOuterMeasure_eq})
\begin{proposition}[Outer measure induced by a set function on a semi-ring] %\mbox{}
  Let \label{P:auss} $\mathcal H$ be a semi-ring and $m: \mathcal H\to\mathbb R_+$ additive and $\sigma$-sub-additive. For $A\subseteq E$ let
  $$ \mu(A) := \inf_{\mathcal G \in \mathcal U(A)} \sum_{G\in\mathcal G} m(G)$$ where
  $$ \mathcal U(A) := \big\{\mathcal G \subseteq_c \mathcal H, A\subseteq \bigcup_{G\in\mathcal G} G\big\}$$
  is the set of countable coverings of $A$. Then, $\mu$ is an outer measure.
\end{proposition}

Moreover, we call a set Carathéodory wrt some outer measure, if it is measurable in the following sense (see \docs{MeasureTheory.OuterMeasure.IsCaratheodory}):

\begin{theorem}[\boldmath $\mu$-measurable sets are a
    $\sigma$-algebra]\label{T:cara} Let $\mu$ be an outer measure on
  $E$ and $\mathcal F$ the set of $\mu$-measurable sets,
  i.e.\ the set of sets $A$ satisfying
  \begin{align*}
    \mu(B) = \mu(B\cap A) + \mu(B\cap A^c), \qquad B \subseteq E.
  \end{align*}
  Then, $\mathcal F$ is a $\sigma$-Algebra and $\mu|_{\mathcal F}$ is
  a measure.
\end{theorem}

In the construction above, since all sets in the semi-ring $\mathcal H$ are Carathéodory (see \docs{isCaratheodory_ofFunction_of_mem}), the $\sigma$-algebra from Theorem~\ref{T:cara} is at least as large as the $\sigma$-algebra generated by $\mathcal H$. The resulting measure is \docs{measureCaratheodory} and agrees with the additive content on $\mathcal H$ (see \docs{measure_eq}). Let us summarize this:

\begin{theorem}[Carathéodory extension]\label{T:masseind}
  Let $\mathcal H$ be a semi-ring and $m: \mathcal H\to\mathbb R_+$
  $\sigma$-finite and $\sigma$-additive. Furthermore, let $\mu$ be the
  induced outer measure from Proposition~\ref{P:auss} and $\mathcal F$
  the $\sigma$-algebra from Theorem~\ref{T:cara}. Then,
  $\sigma(\mathcal H)\subseteq\mathcal F$ and $\mu$ coincides with $m$
  on $\mathcal H$.
\end{theorem}


Apparently, in order to apply Theorem~\ref{T:cara}, we need to show that the additive content is $\sigma$-additive. Note that we can extend an additive content on a semi-ring to an additive content on the ring generated by the semi-ring.

\begin{lemma}
Let $\mathcal H$ be a semi-ring. Then,
\begin{align*}
\mathcal R := \Big\{ \bigcup_{j \in J} A_j : J \text{ finite, } A_j \in \mathcal H, j\in J \text{ disjoint}\Big\} \supseteq \mathcal H
\end{align*}
is a ring. Moreover, if $m$ is an additive content on $\mathcal H$, $m' : \mathcal R \to \mathbb R_+$, defined, for disjoint $(A_j)_{j\in J}$ in $\mathcal H$
$$ m'\Big( \bigcup_{j \in J} A_j \Big) := \sum_{j\in J} m(A_j),$$
extends $m$ to $\mathcal R$.
\end{lemma}

Actually, $\sigma$-additivity and $\sigma$-sub-additivity are close relatives. We have \docs{addContent_iUnion_eq_sum_of_tendsto_zero}, which states that $\sigma$-additivity is implied by continuity in $\emptyset$, and \docs{MeasureTheory.isSigmaSubadditive_of_addContent_iUnion_eq_tsum}, which states that -- if the additive content is defined on a ring, it is $\sigma$-sub-additive if it is $\sigma$-additive. Therefore, we need to show continuity in $\emptyset$. For this, we require the notion of inner regularity with respect to a compact system.

We define inner (and outer) regularity of set functions; see \docs{MeasureTheory.Measure.InnerRegularWRT}.

\begin{definition}[Inner regularity] \label{def:innerreg}
  Let $\alpha$ be some set, equipped with a topology, and $m$ be a
  set-function on some $\mathcal H \subseteq 2^\alpha$.
  \begin{enumerate}
  \item Let $p, q : 2^\alpha \to \{\text{true, false}\}$. Then, $m$ is
    called inner regular with respect to $p$ and $q$, if
    $$ m(A) = \sup\{m(F) : p(F) = \text{true}, F \subseteq A\}$$ for
    all $A \in \mathcal H$ with $q(A) = \text{true}$.
  \item If $q(A) = \text{true}$ iff $A$ is measurable, we neglect the
    {\em and $q$}. If $p(A) = \text{true}$ iff $A$ is closed (compact,
    closed and compact), we say that $m$ is inner regular with respect
    to closed (compact, compact and closed) sets.
  \end{enumerate}
\end{definition}

For the next result, recall that for compact sets $C_1, C_2,...$ with
$\bigcap_{n=1}^\infty C_n = \emptyset$, there is some $N$ with
$\bigcap_{n=1}^N C_n = \emptyset$. More generally, compact sets form a
compact system, which is defined as follows; see \docs{compactSystem}.

\begin{definition}
  Let $\mathcal C \subseteq 2^\alpha$. If, for all $C_1, C_2,...$ with
  $\bigcap_{n=1}^\infty C_n = \emptyset$, there is some $N$ with
  $\bigcap_{n=1}^N C_n = \emptyset$, we call $\mathcal C$ a {\em
    compact system}.
\end{definition}

\noindent
Such compact systems are important since they allow for a proof of continuity at $\emptyset$ (hence $\sigma$-additivity) of a content on a ring, which is the missing piece for applying the Carathéodory Theorem in the proof of the Kolmogorov extension theorem; see \docs{tendsto_zero_of_regular_addContent}.

\begin{lemma}\label{l:stetigcompact}
  Let $\alpha$ $\mu$ be an additive set function on a ring $\mathcal R$, which contains the compact system $\mathcal C$. If $\mu$ is inner regular with respect to $\mathcal C$, then, $\mu$ is continuous at $\emptyset$.
\end{lemma}

\subsection{Kolmogorov's Extension Theorem}
We aim to apply Theorem~\ref{T:cara} on product spaces. The resulting Kolmogorov's extension theorem is a statement about extending a set-function on a product space to a (finite) measure, where the product space can come with an arbitrary index set.  The next definition covers the important concept of a projective family of measures. In short, we define measures on any finite subset of indices in a consistent way.

\begin{definition}[Projective family and projective limit] \mbox{}
  \begin{enumerate}
  \item For some set $\iota$, we will write $J\subseteq_f \iota$ if
    $J\subseteq \iota$ and $J$ is finite.
  \item Let $\iota$ be some (index) set and $(\alpha_i)_{i\in\iota}$ a
    family of sets. For $J\subseteq \iota$, we denote $\alpha_J :=
    \prod_{j \in J} \alpha_j$ and $\pi_J : \alpha_\iota \to \alpha_J$
    the projection. For $H\subseteq J \subseteq \iota$, we write
    $\pi_H^J$ for the projection $\alpha_J \to \alpha_H$.
  \item Let $\mathcal F_i$ be a $\sigma$-algebra in $\alpha_i$,
    $i\in\iota$. For $J\subseteq_f \iota$, let $\mathcal F_J$ be the
    product-$\sigma$-algebra on $\alpha_J$, and $\mathcal F_\iota$ be
    the $\sigma$-algebra generated by cylinder sets
    $\{\pi_J^{-1}\prod_{j\in J} A_j: J \subseteq_f \iota, A_j \in
    \sigma(E_j), j\in J\}$.
  \item A family $(P_J)_{J\subseteq_f I}$, where $P_J$ is a finite
    measure on $\mathcal F_J$, is called projective if
    $$P_H = (\pi_H^{J})_\ast P_J$$ for all
    $H\subseteq J \subseteq_f I$. (Recall that $A \mapsto
    (\pi_H^{J})_\ast P_J(A) := P_J((\pi_H^{J})^{-1}A)$
    is called the image measure of $P_J$ under $\pi_H^{J}$.)
  \item If, for some projective family $(P_J)_{J\subseteq_f \iota}$,
    there is a finite measure $P_\iota$ on $\mathcal F_\iota$ with
    $P_J = (\pi_J)_\ast P_\iota$ for all $J\subseteq_f \iota$, then we
    call $P_\iota$ projective limit of $(P_J)_{J\subseteq_f \iota}$.
  \end{enumerate}
\end{definition}

We use here \docs{isProjective} and \docs{isProjectiveMeasureFamily}. In order to apply this result and show the extension theorem, we need to show that $\{\pi_J^{-1} C: C \in \prod_{j\in J} \alpha_j \text{ compact and closed}\}$ is a compact systems. Note that compact sets are closed in Hausdorff spaces, but we do not have this property since we are working with pseudo-metric spaces. Since Lemma~\ref{l:stetigcompact} gives the $\sigma$-additivity of a \docs{kolContent}, which is defined through the projective family $P$, we have:

Note that we extend standard assumptions in twop directions. First, we allow that $\alpha$ is a dependent type, i.e.\ for every index $t \in \iota$, the state space $\alpha_t$ might be different. Second, all $\alpha_t$ are no necessarily separable, complete metric spaces (or Polish, i.e.\ separable and metrizable through a complete metric), but extended pseudo-metric spaces. Such spaces do not satisfy the frequently used Hausdorff (or t2) property, i.e.\ there can be $x\neq y$ such that all open balls around $x$ and $y$ overlap.  This generalization was only possible since underlying results in mathlib were already provided on the same level of generality.  More precisely, \docs{isCompact_iff_totallyBounded_isComplete}, which shows that a set $A \subseteq \alpha$ is compact iff it is complete and totally bounded (see note~\ref{note:tot}), requires $\alpha$ to be a uniform space (Remark~\ref{rem:uniform}, recall that every metric space is uniform).  We also require the underlying space(s) to be second-countable (used in the proof of Lemma~\ref{L:relcoPol}).  A second-countable uniform space can be made into an (extended) pseudo-metric space (\docs{UniformSpace.pseudoMetrizableSpace}); see also Remark~\ref{rem:uniform} for some more details.

Now we are ready to formulate the Kolmogorov extension theorem:

\begin{theorem}[Kolmogorov extension]\label{T1}
  For all $t\in\iota$, let $\alpha_t$ be a separable, complete
  pseudo-extended-metric space and $\mathcal F_t$ the Borel
  $\sigma$-algebra generated by its topology. Let $(P_J)_{J\subseteq_f
    \iota}$ be a projective family of finite measures and $P$ be
  defined on $\mathcal A := \bigcup_{J \subseteq_f \iota} \mathcal
  F_J$ given by $P(A) = P_J(\pi_J A)$ for $A\in\mathcal F_J$. Then,
  there is a unique extension of $P$ to $\sigma(\mathcal A)$.
\end{theorem}

We now describe the proof of Kolmogorov's extension theorem as well as
its formalization: For the proof of Theorem~\ref{T1}, we
\begin{enumerate}
  \item apply Theorem~\ref{T:masseind} for the ring (hence semi-ring)
    $\mathcal A$ and the set-function $P$ as given in
    Theorem~\ref{T1};
  \item show $\sigma$-additivity (as assumed in
    Theorem~\ref{T:masseind}) of $P$ by using
    Lemma~\ref{l:stetigcompact}. For the latter, we need to show that
    $P$ is inner regular with respect to a compact system. Here, note
    that $\{\pi_J^{-1}C : C \in \prod_{j\in J} \alpha_j \text{ compact
      and closed}\}$ is a compact system and $P(\pi_J^{-1}C) =
    P_J(C)$, so we need to show that $P_J$ is inner regular with
    respect to compact closed sets, $J\subseteq_f \iota$;
  \item use Lemma~\ref{L:relcoPol} in combination with
    Lemma~\ref{l:tight} (1.$\Rightarrow$2.) and the properties of
    completeness, separability of the underlying extended
    pseudo-metric spaces in order to see that every $P_J$ has the
    desired property of being inner regular wrt compact and closed
    sets. This concludes the proof of Theorem~\ref{T1}.
\end{enumerate}
The formalization of this proof resembles these arguments. We leave
out all instances in the reformulation of the result and its proof
(see below Theorem~\ref{T1} for a full formulation):



\section{Gaussian Measures and characteristic functions}

Prior to our work, \mathlib contained the definition of the one-dimensional normal distribution (TODO LINK), but not more general Gaussian measures.

\todor{ General Gaussian def, characteristic function, Fernique's theorem (not in detail), Hilbert spaces defs, stdGaussian and multivariateGaussian.}

\section{The Kolmogorov-Chentsov Theorem}
\label{S:continuity}



\section{Construction of Brownian motion}
\label{S:BM}


\section*{Acknowledgments}

Other contributors, who made one or two PRs: Jonas Bayer, Lorenzo Loccioli, Alessio Rondelli, Jérémy Scanvic

Blueprint: Patrick Massot (citation?)

Project template \cite{Monticone_LeanProject_2025} and technical support: Pietro Monticone

Lean/Mathlib community, Mathlib reviewers (Sébastien Gouëzel in particular?)

%%
%% Bibliography
%%

\printbibliography

\end{document}
